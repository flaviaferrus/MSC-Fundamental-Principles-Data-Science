{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "#### First Name: Flàvia \n",
    "#### Last Name: Ferrús Marimón\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession \n",
    "spark = SparkSession.builder.appName(\"Twitter Analysis\")\\\n",
    ".getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_twitter = spark.read.json(\"corona_tweet_new.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- in_reply_to_status_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user: struct (nullable = true)\n",
      " |    |-- contributors_enabled: boolean (nullable = true)\n",
      " |    |-- created_at: string (nullable = true)\n",
      " |    |-- default_profile: boolean (nullable = true)\n",
      " |    |-- default_profile_image: boolean (nullable = true)\n",
      " |    |-- description: string (nullable = true)\n",
      " |    |-- favourites_count: long (nullable = true)\n",
      " |    |-- follow_request_sent: string (nullable = true)\n",
      " |    |-- followers_count: long (nullable = true)\n",
      " |    |-- following: string (nullable = true)\n",
      " |    |-- friends_count: long (nullable = true)\n",
      " |    |-- geo_enabled: boolean (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- id_str: string (nullable = true)\n",
      " |    |-- is_translator: boolean (nullable = true)\n",
      " |    |-- lang: string (nullable = true)\n",
      " |    |-- listed_count: long (nullable = true)\n",
      " |    |-- location: string (nullable = true)\n",
      " |    |-- name: string (nullable = true)\n",
      " |    |-- notifications: string (nullable = true)\n",
      " |    |-- profile_background_color: string (nullable = true)\n",
      " |    |-- profile_background_image_url: string (nullable = true)\n",
      " |    |-- profile_background_image_url_https: string (nullable = true)\n",
      " |    |-- profile_background_tile: boolean (nullable = true)\n",
      " |    |-- profile_banner_url: string (nullable = true)\n",
      " |    |-- profile_image_url: string (nullable = true)\n",
      " |    |-- profile_image_url_https: string (nullable = true)\n",
      " |    |-- profile_link_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_border_color: string (nullable = true)\n",
      " |    |-- profile_sidebar_fill_color: string (nullable = true)\n",
      " |    |-- profile_text_color: string (nullable = true)\n",
      " |    |-- profile_use_background_image: boolean (nullable = true)\n",
      " |    |-- protected: boolean (nullable = true)\n",
      " |    |-- screen_name: string (nullable = true)\n",
      " |    |-- statuses_count: long (nullable = true)\n",
      " |    |-- time_zone: string (nullable = true)\n",
      " |    |-- translator_type: string (nullable = true)\n",
      " |    |-- url: string (nullable = true)\n",
      " |    |-- utc_offset: string (nullable = true)\n",
      " |    |-- verified: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_twitter.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### From the user nestec col select the following cols only id_str,followers_count,friends_count and created at \n",
    "# (2 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- hashtags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- in_reply_to_status_id: string (nullable = true)\n",
      " |-- in_reply_to_user_id_str: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- reply_count: long (nullable = true)\n",
      " |-- retweet_count: long (nullable = true)\n",
      " |-- source: string (nullable = true)\n",
      " |-- user_id_str: string (nullable = true)\n",
      " |-- user_followers_count: long (nullable = true)\n",
      " |-- user_friends_count: long (nullable = true)\n",
      " |-- user_created_at: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Select only the required columns from the nested user struct column\n",
    "user_cols = [\"id_str\", \"followers_count\", \"friends_count\", \"created_at\"]\n",
    "user_sub_df = df_twitter.select([col(\"user.\"+c).alias(\"user_\"+c) for c in user_cols])\n",
    "\n",
    "# Join the original DataFrame with the extracted user sub-DataFrame\n",
    "df_twitter1 = df_twitter.join(user_sub_df, how=\"left\")\n",
    "\n",
    "# Drop the original nested user column\n",
    "df_twitter1 = df_twitter1.drop(\"user\")\n",
    "\n",
    "# Print the resulting schema\n",
    "df_twitter1.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252619236"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the total count of number of records in df_twitter(1 point)\n",
    "df_twitter1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the source lable from source col by droping the anchor tab and save it as another col named extracted_source\n",
    "# for example <a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a> => Twitter Web App\n",
    "# you can use \"<a [^>]+>([^<]+)\" as regular expresion and the group would be 1 for this regular expression.\n",
    "#(4 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|extracted_source|              source|\n",
      "+----------------+--------------------+\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "| Twitter Web App|<a href=\"https://...|\n",
      "+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "# Extract the source label from the source column using a regular expression\n",
    "df_twitter2 = df_twitter1.withColumn(\"extracted_source\", regexp_extract(col(\"source\"), '<a [^>]+>([^<]+)', 1))\n",
    "\n",
    "# Select the extracted_source and source columns and show the resulting DataFrame\n",
    "df_twitter2.select(col('extracted_source'), col('source')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|   extracted_source|              source|\n",
      "+-------------------+--------------------+\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "| Twitter for iPhone|<a href=\"http://t...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "|Twitter for Android|<a href=\"http://t...|\n",
      "|    Twitter Web App|<a href=\"https://...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the source lable from source col by droping the anchor tab and save it as another col named extracted_source\n",
    "# for example <a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a> => Twitter Web App\n",
    "# you can use \"<a [^>]+>([^<]+)\" as regular expresion and the group would be 1 for this regular expression.\n",
    "#(4 points)\n",
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "df_twitter=df_twitter.<FILL_IN>\n",
    "df_twitter.select(col('extracted_source'),col('source')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the DataFrame into RDD\n",
    "rdd_twitter=df_twitter2.rdd.map(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a temporay table in memory with name as twitter (1 point)\n",
    "df_twitter2.createOrReplaceTempView(\"twitter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mon Apr 20 15:01:57 +0000 2020',\n",
       "  5545,\n",
       "  [],\n",
       "  '1252251164227362821',\n",
       "  None,\n",
       "  None,\n",
       "  'India',\n",
       "  3460,\n",
       "  5477,\n",
       "  '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  '93612837',\n",
       "  121,\n",
       "  759,\n",
       "  'Mon Nov 30 11:38:08 +0000 2009',\n",
       "  'Twitter Web App'),\n",
       " ('Mon Apr 20 15:01:57 +0000 2020',\n",
       "  5545,\n",
       "  [],\n",
       "  '1252251164227362821',\n",
       "  None,\n",
       "  None,\n",
       "  'India',\n",
       "  3460,\n",
       "  5477,\n",
       "  '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
       "  '346443880',\n",
       "  208,\n",
       "  1196,\n",
       "  'Mon Aug 01 08:15:42 +0000 2011',\n",
       "  'Twitter Web App')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_twitter.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Data\n",
    "\n",
    "#### You will be writing code to find the answer to the questions listed below using Just RDD, Using spark SQL \n",
    "\n",
    "- Analyze using RDD \n",
    "- Analyze using Dataframe without temp table \n",
    "- Analyze using spark.sql with temp table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Get total number of unique users (1 point for each type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using RDD\n",
    "\n",
    "## We need to get the total number of rows with unique user_id_str\n",
    "\n",
    "import pyspark\n",
    "#sc = pyspark.SparkContext('local[*]')\n",
    "# Display the type of the Spark Context sc\n",
    "#type(sc)\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Big Data Assisgnment 2\") \\\n",
    "    .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'93612837'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find the index of the column where we have the user id\n",
    "rdd_twitter.first()[10]\n",
    "\n",
    "## This is the id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#unique_users = rdd_twitter.map(lambda x: x[10]).distinct().count()\n",
    "#print(unique_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that this code takes a lot of memory, since the function `distinct` is not the optimum way to compute the unique number of users from the dataset. \n",
    "\n",
    "Observe that we can get the unique number of users by applying an alternative `rdd` code in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = rdd_twitter.map(lambda x: (x.user_id_str, 1))\n",
    "\n",
    "unique_users2 = users.reduceByKey(lambda a, b : a+b)\n",
    "## Could have used distinct()\n",
    "uniqueUserCount = unique_users2.count()\n",
    "print ('Unique hosts: %d' % uniqueUserCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame\n",
    "unique_users_df = df_twitter2.select(\"user_id_str\").distinct().count()\n",
    "print(\"Total number of unique users: \", unique_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table.\n",
    "\n",
    "## We use the table we have created, this is:\n",
    "\n",
    "#df_twitter2.createOrReplaceTempView(\"twitter\")\n",
    "\n",
    "# Count the total number of unique users\n",
    "unique_users_sql = spark.sql(\"SELECT COUNT(DISTINCT user_id_str) FROM twitter\")\n",
    "\n",
    "# Print the result\n",
    "print(unique_users_sql.first()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Get count of user who have more than 1 tweet in the data (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Get total number unique extracted_source (1 point each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Get top 5 most used extracted_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Get count of distinct hastags used ( 5 point each) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Get top 5 hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD (4 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 Get total number of tweets which are retweeted more than 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 Get top 3 most retweeted tweets per country (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.9 Total number of tweets per country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using RDD (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spark.sql and the temporay table. (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 save the data such that you have seperate folder per country (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Save the data as parquet files (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DataFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
