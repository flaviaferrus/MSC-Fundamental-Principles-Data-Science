{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pill 3: About performance\n",
    "\n",
    "**Outline**\n",
    "\n",
    "+ Accuracy metrics\n",
    "    + Error and accuracy\n",
    "    + Receiver operating curve\n",
    "    + Area under the curve\n",
    "    \n",
    "+ Model selection II. Crossvalidation.\n",
    "\n",
    "+ The unbalanced problem.\n",
    "\n",
    "+ Confusion matrix and partial performance measurements.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1. More about the 'Churn' problem and accuracy metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling churn means to understand what keeps the customer engaged to our product. Its analysis goal is to predict or describe the **churn rate** i.e. the rate at which customer leave or cease the subscription to a service. Its value lies in the fact that engaging new customers is often more costly than retaining existing ones. For that reason subscription business-based companies usually have proactive policies towards customer retention.\n",
    "\n",
    "In this case study, we aim at building a machine learning based model for customer churn prediction on data from a Telecom company. Each row on the dataset represents a subscribing telephone customer. Each column contains customer attributes such as phone number, call minutes used during different times of day, charges incurred for services, lifetime account duration, and whether or not the customer is still a customer.\n",
    "\n",
    "This case is partially inspired in Eric Chiang's analysis of churn rate. Data is available from the University of California Irvine machine learning repositories data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The complete set of attributes is the following:\n",
    "\n",
    "+ State: categorical, for the 50 states and the District of Columbia\n",
    "+ Account length: integer-valued, how long an account has been active \n",
    "+ Area code: categorical\n",
    "+ Phone number: customer ID\n",
    "+ International Plan: binary feature, yes or no\n",
    "+ VoiceMail Plan: binary feature, yes or no\n",
    "+ Number of voice mail messages: integer-valued\n",
    "+ Total day minutes: continuous, minutes customer used service during the day\n",
    "+ Total day calls: integer-valued\n",
    "+ Total day charge: continuous\n",
    "+ Total evening minutes: continuous, minutes customer used service during the evening\n",
    "+ Total evening calls: integer-valued\n",
    "+ Total evening charge: continuous\n",
    "+ Total night minutes: continuous, minutes customer used service during the night\n",
    "+ Total night calls: integer-valued\n",
    "+ Total night charge: continuous\n",
    "+ Total international minutes: continuous, minutes customer used service to make international calls\n",
    "+ Total international calls: integer-valued\n",
    "+ Total international charge: continuous\n",
    "+ Number of calls to customer service: integer-valued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names:\n",
      "['State', 'Account Length', 'Area Code', 'Phone', \"Int'l Plan\", 'VMail Plan', 'VMail Message', 'Day Mins', 'Day Calls', 'Day Charge', 'Eve Mins', 'Eve Calls', 'Eve Charge', 'Night Mins', 'Night Calls', 'Night Charge', 'Intl Mins', 'Intl Calls', 'Intl Charge', 'CustServ Calls', 'Churn?']\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account Length</th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Int'l Plan</th>\n",
       "      <th>VMail Plan</th>\n",
       "      <th>Night Charge</th>\n",
       "      <th>Intl Mins</th>\n",
       "      <th>Intl Calls</th>\n",
       "      <th>Intl Charge</th>\n",
       "      <th>CustServ Calls</th>\n",
       "      <th>Churn?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AL</td>\n",
       "      <td>118</td>\n",
       "      <td>510</td>\n",
       "      <td>391-8027</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>9.18</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>False.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account Length  Area Code     Phone Int'l Plan VMail Plan  \\\n",
       "0    KS             128        415  382-4657         no        yes   \n",
       "1    OH             107        415  371-7191         no        yes   \n",
       "2    NJ             137        415  358-1921         no         no   \n",
       "3    OH              84        408  375-9999        yes         no   \n",
       "4    OK              75        415  330-6626        yes         no   \n",
       "5    AL             118        510  391-8027        yes         no   \n",
       "\n",
       "   Night Charge  Intl Mins  Intl Calls  Intl Charge  CustServ Calls  Churn?  \n",
       "0         11.01       10.0           3         2.70               1  False.  \n",
       "1         11.45       13.7           3         3.70               1  False.  \n",
       "2          7.32       12.2           5         3.29               0  False.  \n",
       "3          8.86        6.6           7         1.78               2  False.  \n",
       "4          8.41       10.1           3         2.73               3  False.  \n",
       "5          9.18        6.3           6         1.70               0  False.  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "churn_df = pd.read_csv('./files/churn.csv')\n",
    "col_names = churn_df.columns.tolist()\n",
    "\n",
    "print (\"Column names:\")\n",
    "print (col_names)\n",
    "\n",
    "to_show = col_names[:6] + col_names[-6:]\n",
    "\n",
    "print (\"\\nSample data:\")\n",
    "churn_df[to_show].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature space holds 3333 observations and 18 features\n",
      "Unique target labels: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Isolate target data\n",
    "churn_result = churn_df['Churn?']\n",
    "y = np.where(churn_result == 'True.',1,0)\n",
    "\n",
    "# We don't need these columns\n",
    "to_drop = ['State','Phone','Churn?']\n",
    "churn_feat_space = churn_df.drop(to_drop,axis=1)\n",
    "\n",
    "# 'yes'/'no' has to be converted to boolean values\n",
    "# NumPy converts these from boolean to 1. and 0. later\n",
    "yes_no_cols = [\"Int'l Plan\",\"VMail Plan\"]\n",
    "churn_feat_space[yes_no_cols] = churn_feat_space[yes_no_cols] == 'yes'\n",
    "\n",
    "# Pull out features for future use\n",
    "features = churn_feat_space.columns\n",
    "\n",
    "X = churn_feat_space.values.astype(np.float)\n",
    "\n",
    "print (\"Feature space holds %d observations and %d features\" % X.shape)\n",
    "print (\"Unique target labels:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 More about model selection: Cross-validation\n",
    "\n",
    "We saw in former pills that a nice way of assessing performance or comparing models is simulating the exploitation stage. Remember that this was done splitting the data set in training, validation and test sets. Because this splitting process has a randomness involved the resulting performance metric is also a random varible and the instantaneous value of the variable is heavily affected by the split. It can be the case that the split is very favorable and we get awesome performance metric values, or the other way around. We suggested the posibility of doing this same proces many times to get a good picture of the real behavior of the classifier. This is a perfectly correct way for assessing the performance. However one could argue that some points can be never chosen for testing, or that some points can be shared accross the different training splits. These could bias the result.\n",
    "\n",
    "Another well founded approach in order to circumvent the former problem is what we call **cross-validation**. The idea behind this process is that each point will be used for testing purposes. The most well known cross-validation techniques are:\n",
    "\n",
    "+ **Leave one out (LOO)**: Leave one out is as follows,\n",
    "    + Take one sample of the data set $x_i$.\n",
    "    + Train the classfier with all the data set except for the data selected $X_{train} = \\{X\\}\\setminus x_i$.\n",
    "    + Test the classifier on $x_i$ and store the result.\n",
    "    + Repeat the process for all samples of the data set.\n",
    "    + At the end of the process you should have an array with all the results ready for the computation of a performance metric.\n",
    "    \n",
    "Leave-one-out is computationally intensive, because it requires training a classifier as many times as examples in the data set we have. In order to alleviate this computational burden we can define the following process \n",
    "\n",
    "+ **K-fold cross-validation**: \n",
    "\n",
    "    + Split the data set in K disjoint subsets with the same cardinality, i.e. $\\{X\\} = S_1 \\cup S_2 \\dots \\cup S_k$ where $S_i \\subset \\{X\\}$, $S_i \\cap S_j = \\emptyset,  i\\neq j$, and $|S_i|\\approx |S_j|,  \\forall i, j$.\n",
    "    + Select one of the subsets $S_i$. This will be used as test set.\n",
    "    + Train the classfier in all except that subset, i.e. $X_{train} = \\{X\\} \\setminus S_i$.\n",
    "    + Test the trained classifier with $S_i$ and store the individual results for each sample in the subset (we can also consider the partial performance statistics in the subset for other hint on performance)\n",
    "    + Repeat for each subset\n",
    "    + At the end of the process you should have an array with all individual results ready for the computation of a performance metric. \n",
    "    \n",
    "This second approach is subject to some variability in the splitting process. Thus the resulting performance metric is again a random variable. One can repeat this process several times to estimate statistics such as the mean and variance of the classifier. Sometimes you will see partial performance statistics of each fold aggregated as simple way for approximating the process statistics.\n",
    "\n",
    "Leave one out can be seen as a particular instance of K-fold cross validation with K equal to the cardinality of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us practice this with the churn problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv = model_selection.KFold(n_splits = 3 ,shuffle=True ,random_state=42)\n",
    "cv.get_n_splits(X)\n",
    "\n",
    "yhat = np.zeros((X.shape[0],1))\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    X_train,y_train = X[train_idx,:],y[train_idx]\n",
    "    X_test,y_test = X[test_idx,:],y[test_idx]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled=scaler.fit_transform(X_train)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators = 11)\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    yhat[test_idx] = clf.predict(X_test_scaled).reshape(-1,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9441944194419442\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print ('Accuracy score: ' + str(metrics.accuracy_score(yhat,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px\"><b>EXERCISE:</b> Let us check the performance for different values of `K = {2,3,5,10,20}`. In order to assess the variance of the process let us repeat each cross-validation `50` times. Show a box plot comparing the performances of the three methods.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code\n",
    "arrayK = np.array([2,3,5,10,20])\n",
    "acc=np.zeros((len(arrayK), 50))\n",
    "iterationK = 0\n",
    "for k in arrayK:\n",
    "    for i in range(0,50):\n",
    "        X = churn_feat_space.values.astype(np.float)\n",
    "        cv = model_selection.KFold(n_splits = k ,shuffle=True ,random_state=42)\n",
    "        cv.get_n_splits(X)\n",
    "        yhat = np.zeros((X.shape[0],1))\n",
    "        for train_idx, test_idx in cv.split(X):\n",
    "            X_train,y_train = X[train_idx,:],y[train_idx]\n",
    "            X_test,y_test = X[test_idx,:],y[test_idx]\n",
    "    \n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled=scaler.fit_transform(X_train)\n",
    "    \n",
    "            clf = RandomForestClassifier(n_estimators = 11)\n",
    "            clf.fit(X_train_scaled,y_train)\n",
    "    \n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "            yhat[test_idx] = clf.predict(X_test_scaled).reshape(-1,1)\n",
    "        acc[iterationK, i] = metrics.accuracy_score(yhat,y)\n",
    "    iterationK +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc.shape\n",
    "acc.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partial_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/df/4599m83s2vj4j1_h__gx7kqw0000gn/T/ipykernel_1086/64927679.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using the full set statistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using partial statistics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partial_acc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.boxplot(acc.T)\n",
    "plt.gca().set_ylim([0.92,0.98])\n",
    "plt.title('Using the full set statistic')\n",
    "plt.subplot(122)\n",
    "plt.boxplot(partial_acc)\n",
    "plt.title('Using partial statistics')\n",
    "plt.gca().set_ylim([0.92,0.98])\n",
    "plt.gcf().set_size_inches(14,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: I don't know what the partial accuracy is supposed to be. Is it partial fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'partial_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/df/4599m83s2vj4j1_h__gx7kqw0000gn/T/ipykernel_1086/2326061858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using the full set statistic'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m122\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using partial statistics'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.92\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'partial_acc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.boxplot(acc)\n",
    "plt.gca().set_ylim([0.92,0.98])\n",
    "plt.title('Using the full set statistic')\n",
    "plt.subplot(122)\n",
    "plt.boxplot(partial_acc)\n",
    "plt.title('Using partial statistics')\n",
    "plt.gca().set_ylim([0.92,0.98])\n",
    "plt.gcf().set_size_inches(14,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Unbalanced datasets and the need for other kind of performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pie(np.c_[len(y)-np.sum(y),np.sum(y)][0],labels=['No Churn','Churn'],colors=['r','g'],shadow=True,autopct ='%.2f' )\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(6,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "**Unbalanced datasets**\n",
    "<p>\n",
    "The unbalanced term describes the condition of the data where the ratio between the sizes of the positive and negative is a small value. In those scenarios, always predicting the majority class usually yields good accuracy performance, though it is ill informative. This kind of problems is very common when we want to model unusual events such as rare diseases, the occurrence of a failure in machinery, credit card fraud operations, etc. In those scenarios gathering data from usual events is very easy but collecting data from unusual events is difficult and results in a comparatively small size data set. In order to measure the performance on those data sets one has to use other performance metrics, such as specificity or positive predictive value on the minority class. In the end, the value of a misclassification of a sample depends on the application and the user. For example, in cancer detection because the cost of missing one patient in a trial is very large, we want the predictor to have very large sensitivity (we do not accept false negatives) though it means accepting more false positives. These false positives can be discarded in subsequent tests. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although accuracy is the most normal metric for evaluating classifiers, there are cases when the business value of correctly predicting elements from one class is different from the value for the prediction of elements of another class. In those cases, accuracy is not a good performance metric and more detailed analysis is needed. The **confusion matrix** enables us to define different metrics considering such scenarios. The confusion matrix considers the concepts of the classifier outcome and the actual ground truth or gold standard. In a binary problem, there are four possible cases: \n",
    "\n",
    "\n",
    "+ *True positives (TP):* When the classifier predicts a sample as positive and it really is positive.\n",
    "+ *False positives (FP):* When the classifier predicts a sample as positive but in fact it is negative.\n",
    "+ *True negatives (TN):* When the classifier predicts a sample as negative and it really is negative.\n",
    "+ *False negatives (FN):* When the classifier predicts a sample as negative but in fact it is positive.\n",
    "\n",
    "\n",
    "We can summarize this information in a matrix, namely the confusion matrix, as follows:\n",
    "<img src = \"./files/confmat.png\" width = 800px>\n",
    "The combination of these elements allows us to define several performance metrics:\n",
    "\n",
    "\n",
    "+ *Accuracy:*\n",
    "$$\\text{accuracy}=\\frac{\\text{TP}+\\text{TN}}{\\text{TP}+\\text{TN}+\\text{FP}+\\text{FN}}$$\n",
    "\n",
    "+ Column-wise we find these two partial performance metrics:\n",
    " + *Sensitivity or Recall:*\n",
    "$$\\text{sensitivity}=\\frac{\\text{TP}}{\\text{Real Positives}}=\\frac{\\text{TP}}{\\text{TP}+\\text{FN}}$$\n",
    " + *Specificity:*\n",
    "$$\\text{specificity}=\\frac{\\text{TN}}{\\text{Real Negatives}}=\\frac{\\text{TN}}{\\text{TN}+\\text{FP}}$$\n",
    "\n",
    "+ Row-wise we find these two partial performance metrics:}\n",
    "    + *Precision or Positive Predictive Value:*\n",
    "$$\\text{precision}=\\frac{\\text{TP}}{\\text{Predicted Positives}}=\\frac{\\text{TP}}{\\text{TP}+\\text{FP}}$$\n",
    "    + *Negative predictive value:*\n",
    "$$\\text{NPV}=\\frac{\\text{TN}}{\\text{Predicted Negative}}=\\frac{\\text{TN}}{\\text{TN}+\\text{FN}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class= \"alert alert-danger\" style = \"border-radius:10px\"> **QUIZ:** Consider the following questions and answer accordingly.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us code the confusion matrix and the different metrics for the churn problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import model_selection\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "yhat = clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 43\n",
      "109 814\n"
     ]
    }
   ],
   "source": [
    "TP = np.sum(np.logical_and(yhat==y_test,yhat==1))\n",
    "TN = np.sum(np.logical_and(yhat==y_test,yhat==0))\n",
    "FP = np.sum(np.logical_and(yhat!=y_test,yhat==1))\n",
    "FN = np.sum(np.logical_and(yhat!=y_test,yhat==0))\n",
    "\n",
    "print (TP,FP)\n",
    "print (FN,TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[814 109]\n",
      " [ 43  34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#I use wikipedia notation, thus we have to swap predictions and groundtruth\n",
    "print (metrics.confusion_matrix(yhat,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91       857\n",
      "           1       0.44      0.24      0.31       143\n",
      "\n",
      "    accuracy                           0.85      1000\n",
      "   macro avg       0.66      0.59      0.61      1000\n",
      "weighted avg       0.82      0.85      0.83      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (metrics.classification_report(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Another interesting metric is *F1-score*. This is defined as follows,\n",
    "\n",
    "$\\text{F1-score} = 2\\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision}+\\text{recall}} = 2\\frac{\\frac{TP}{TP+FP}\\frac{TP}{TP+FN}}{\\frac{TP}{TP+FP}+\\frac{TP}{TP+FN}} = \\frac{2 TP}{TP+FN+TP+FP} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style= \"border-radius:10px\">**QUESTION:** Why `classification_report` only reports precission and recall?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Precission indicates the proportion of true positives detected among the real amount of positives. Similarly Recall indicates the proportion of the true positive among all the positives detected (or predicted). Note that we are interested on how well the model predicts the positive samples, we are interested in detecting well the poisitive cases, we are focusing on reducing the false negatives, and in exchange we pay the price to allow more false negative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Operating point, ROC, and Area under the curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many classifiers can be considered as thresholded regressors. This means that the actual classifier actually reports some score that has to be further thresholded to finally decide the class. Consider, as an example, a binary classifier that scores the probability of belonging to class 'A', i.e. $P(x \\in 'A')$. Obviously, $1 - P(x \\in 'A')$ is the probability of belonging to class 'B'. The decision of belonging to class 'A' is given by $P(x \\in 'A')>thr$. We usually will use $thr = 0.5$ but we could change this threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px\">**QUESTION:** What is the effect of lowering the value of the threshold in the four partial performance metrics? Consider what happens to the positive samples ('A') and to the negative samples ('B')</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** If we lower the threshold, the decision of belonging to class A (positive) is given with lower probability than initially, i.e. we may consider a sample to be positive easily, then we will have more FALSE POSITIVE. Similarly, we are increasing the value from which we consider a sample to be of class B (negative) then we may have less FALSE NEGATIVE:\n",
    "- Precision: true positive among the real positives: may be greater (we may have more positives all in all, so the predicted positives will be more than before, while the number of real positives is fixed)\n",
    "- Recall: true positive among the predicted positives: may be lower (we will have more positives at the end, and maybe more false negatives, decreasing the proportio)\n",
    "- Specificity: true negatives among the real negatives: lower\n",
    "- Negative predictive value: true negative among the predicted negative: greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that we can control the amount of true positive and the amount of false positives.This gives rise to the concept of the **operating point**. The operating point is the precise threshold we select for an specific application by controlling the true positive rate (recall) vs the false positive rate (1- specificity = FP / (FP+TN)). We can plot all the operating points by varying the threshold value and ploting the precission versus the recall. This curve is called **Receiver Operating Characteristic**. It shows how the true positive rate changes when the false positive rate change.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It also means that we can control precision and recall by modifying this threshold. \n",
    " This also allow us to define the **Precision-Recall curve**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 The perfect curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve tells us about the behavior of the positive class, displaying how the true positive rate changes as we change the false positive rate. Note that the curve depends on all the terms of the confusion matrix:\n",
    "\n",
    "\n",
    "$$TPR = sensitivity \\;(recall) = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "$$FPR = 1-specificity = \\frac{FP}{TN+FP}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-danger\" style=\"border-radius:10px\"> **QUIZ** In the case of a perfect classification, what are the values of TPR and FRP ?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Perfect classification means there are no false positive nor false negatives. Then $FN=0=FP$, and we have $TPR=1$, and $FPR=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Computing the curve\n",
    "\n",
    "Let us compute the curve. In order to do so we need the score from a classifier. Some classifiers in sklearn have the method `predict_proba` that returns the \"confidence\" of the classification. Let us do this,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn import model_selection\n",
    "\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=21)\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.3,random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "yhat = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = clf.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85714286, 0.14285714],\n",
       "       [0.85714286, 0.14285714],\n",
       "       [0.9047619 , 0.0952381 ],\n",
       "       ...,\n",
       "       [0.80952381, 0.19047619],\n",
       "       [0.95238095, 0.04761905],\n",
       "       [0.85714286, 0.14285714]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = np.sum(np.logical_and(yhat==y_test,yhat==1))\n",
    "TN = np.sum(np.logical_and(yhat==y_test,yhat==0))\n",
    "FP = np.sum(np.logical_and(yhat!=y_test,yhat==1))\n",
    "FN = np.sum(np.logical_and(yhat!=y_test,yhat==0))\n",
    "\n",
    "TPR = TP /(TP+FN)\n",
    "FPR = FP /(FP+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.16783216783216784, 0.007001166861143524)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(TPR),np.sum(FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=np.argsort(score[:,1])\n",
    "\n",
    "TPR = []\n",
    "FPR = []\n",
    "for i in idx:\n",
    "    yhat = np.where(score[:,1]>score[i,1],1.0,0.0)\n",
    "    TP = np.sum(np.logical_and(yhat==y_test,yhat==1.))\n",
    "    TN = np.sum(np.logical_and(yhat==y_test,yhat==0.))\n",
    "    FP = np.sum(np.logical_and(yhat!=y_test,yhat==1.))\n",
    "    FN = np.sum(np.logical_and(yhat!=y_test,yhat==0.))\n",
    "\n",
    "    TPR.append( TP /(TP+FN) )\n",
    "    FPR.append( FP /(FP+TN) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8f19835460>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.argsort(FPR)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.array(FPR)[idx],np.array(TPR)[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8f196960d0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr,_ = metrics.roc_curve(y_test,score[:,1])\n",
    "fig = plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "plt.plot(np.array(FPR)[idx],np.array(TPR)[idx],'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He,he! The same result as sklearn ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\" style = \"border-radius:10px\">**QUESTION:** What is the operating point?</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Area under the curve\n",
    "\n",
    "The area under the curve is a good value for summarizing the ROC behavior. Although not perfect it gives a good idea for comparing classifiers. Let us compute the Area under the curve using the trapezoid method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_AUC(tpr,fpr):\n",
    "    val,idx = np.unique(fpr,return_index = True)\n",
    "    auc = 0\n",
    "    N = len(idx)-1 \n",
    "    for i in range(N):\n",
    "        auc  = auc + tpr[idx[i]]*(fpr[idx[i+1]]-fpr[idx[i]]) + (tpr[idx[i+1]]-tpr[idx[i]])*(fpr[idx[i+1]]-fpr[idx[i]])/2\n",
    "    auc = auc + tpr[idx[i+1]]*(1.-fpr[idx[i+1]]) + (1.-tpr[idx[i+1]])*(1.-fpr[idx[i+1]])/2\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7439229382053185"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_AUC(tpr,fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7439555776778648"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh!!!! Awesome, nearly the same ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Comparing classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare some classifiers in the problem of `Churn?` and check which one works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-success\" style = \"border-radius:10px\">**EXERCISE: ** Compare a linear support vector machine, random forest, `11`-nearest neighbor, and logistic regression in the problem of Churn. \n",
    "<ol>\n",
    "<li>Split data in training and test, `test_size = 0.3`, `random_state = 0`.</li>\n",
    "<li>Draw in a single plot the four curves.</li>\n",
    "<li>Compute the area under the curve.</li>\n",
    "</ol>\n",
    "\n",
    "**HINT: ** In order to get the confidence/margin in the SVM use the method `decision_function`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/flaviaferrusmarimon/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Your code\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import model_selection\n",
    "from sklearn import tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "model2= tree.DecisionTreeClassifier()\n",
    "model1 = svm.SVC(C=100.0,gamma = 1e-5,random_state=42)\n",
    "model3 = neighbors.KNeighborsClassifier(n_neighbors=11)\n",
    "model4 = LogisticRegression(random_state=0)\n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "model2.fit(X_train,y_train)\n",
    "model3.fit(X_train,y_train)\n",
    "model4.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "yhat1 = model1.predict(X_test)\n",
    "yhat2 = model2.predict(X_test)\n",
    "yhat3 = model3.predict(X_test)\n",
    "yhat4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.57590696e-01 -8.97841079e-01 -1.03594989e+00 -1.77112367e+00\n",
      "  4.09809229e+00 -8.84137031e-01 -1.36855624e+00 -1.70951207e+00\n",
      " -1.46138460e+00 -5.92454626e-01 -1.21458909e+00 -1.38502150e+00\n",
      " -1.24085417e+00 -1.71878743e+00  3.82496673e-01 -6.85057359e-01\n",
      " -1.22238154e+00 -6.60461655e-01 -1.13486265e+00 -1.37768394e+00\n",
      " -1.68659573e+00 -1.67737523e+00 -1.86567562e+00 -9.67703503e-01\n",
      " -1.46648937e+00 -1.81399528e+00 -1.07846197e+00 -1.04671965e+00\n",
      " -1.11261917e+00 -1.35802855e+00 -1.77015528e+00 -1.85597453e+00\n",
      " -2.24509966e+00 -1.04547712e+00 -1.21076728e+00 -1.20701452e+00\n",
      "  1.11927747e+00 -1.38118024e+00 -1.29905487e+00  7.65205558e-02\n",
      " -1.48388498e+00  8.02738997e-01  1.86396985e+00 -7.08121232e-01\n",
      " -1.53653272e+00 -8.34074657e-01 -2.15264867e+00 -1.85806925e+00\n",
      " -8.68368302e-01 -8.07669339e-01 -1.36343677e+00 -1.29573336e+00\n",
      " -7.77530770e-01 -1.66419167e+00 -1.35809603e+00 -1.50039184e+00\n",
      " -1.67136124e+00 -9.11983690e-01 -1.51233858e+00 -4.72997635e-02\n",
      "  1.79746233e+00 -1.48726451e+00 -9.52872324e-01 -2.50805477e+00\n",
      " -1.02647866e+00 -2.06474161e+00 -1.23629942e+00 -4.88688594e-01\n",
      " -1.24798730e+00 -1.22831441e+00 -1.32114991e+00 -9.31680573e-01\n",
      " -1.29852288e+00  1.91557186e-01 -7.80855375e-01 -9.25109497e-01\n",
      " -8.21741128e-01 -1.33709977e+00 -1.16769463e+00 -8.40268197e-01\n",
      " -1.52095642e+00 -1.38095040e+00 -1.21686335e+00 -1.53301099e+00\n",
      " -1.22108849e+00 -1.51540131e+00 -1.41704207e+00 -1.49892700e+00\n",
      "  4.04188488e-01 -9.66653988e-01 -2.23688537e+00 -9.45654433e-01\n",
      " -1.95246090e+00 -1.43811633e+00 -1.07827245e+00 -8.90948930e-01\n",
      " -1.62998029e+00 -1.39750110e+00 -1.67915300e+00 -1.32612104e+00\n",
      " -1.97548961e+00 -1.96305639e+00 -1.00010381e+00 -1.23549253e+00\n",
      " -9.71330304e-01 -1.18671291e+00 -1.59834951e+00 -1.43909538e+00\n",
      " -9.17431275e-01 -1.57965358e+00 -1.27077361e+00 -8.31785229e-01\n",
      " -1.34467585e+00 -1.80652391e+00 -1.14801252e+00 -1.16595070e+00\n",
      " -1.31729398e+00 -1.49012006e+00 -1.22226616e+00 -1.33476699e+00\n",
      " -1.65295578e+00 -1.14209248e+00 -1.65503964e+00 -8.87098107e-01\n",
      " -6.84171181e-01 -1.12231833e+00 -1.45754896e+00 -1.19855563e+00\n",
      " -1.61290293e+00 -8.33207662e-01 -1.15319318e+00 -9.24068418e-01\n",
      " -1.43005106e+00 -1.55104475e+00 -9.46970054e-01 -1.12993890e+00\n",
      " -1.61949165e+00 -8.81002266e-01 -8.77306696e-01 -2.29356355e+00\n",
      " -1.64517255e+00 -1.55322483e+00  6.56387037e-01 -1.10480589e+00\n",
      " -1.81941008e+00 -9.97219106e-01 -1.34158333e+00 -1.67603795e+00\n",
      " -1.50968163e+00 -1.46466224e+00 -8.48530426e-01 -1.29654695e+00\n",
      " -9.65465034e-01 -1.49179989e+00 -1.13955179e+00 -1.06275622e+00\n",
      " -1.30633108e+00 -1.41947635e+00 -3.70326006e-01 -2.02487217e+00\n",
      " -1.40680894e+00 -1.45375902e+00 -6.36664145e-01 -9.42739770e-01\n",
      "  1.07659164e-01 -9.47913484e-01  3.23262877e+00 -9.48849851e-01\n",
      " -9.30514241e-01  2.43715835e-02 -1.07640815e+00 -1.10161808e+00\n",
      " -1.16762032e+00 -1.19098188e+00 -1.55404964e+00 -5.48409403e-01\n",
      " -7.08619897e-01 -9.54358126e-01 -7.15503959e-01 -1.18537214e+00\n",
      " -5.64101705e-01 -9.50644194e-01 -9.08386206e-01 -1.39043699e+00\n",
      " -9.92700290e-01 -7.07045830e-01 -7.90686255e-01 -1.44299838e+00\n",
      " -1.42400352e+00  6.44915596e+00 -1.22053124e+00 -1.64015516e+00\n",
      " -1.63703381e+00 -1.24689683e+00 -9.66924284e-01 -1.40071235e+00\n",
      " -1.33030094e+00 -1.58212413e+00 -1.37482986e+00 -1.50733527e+00\n",
      " -1.45001247e+00 -1.23506422e+00 -1.19562298e+00 -1.33390487e+00\n",
      " -1.53220477e+00 -1.77180891e+00 -1.29885549e+00 -1.63998809e+00\n",
      " -1.49059431e+00 -5.98364132e-01 -1.56060752e+00 -1.78898679e+00\n",
      "  5.04798336e-01 -1.07448241e+00 -1.47017434e+00 -1.00909646e+00\n",
      " -1.12210685e+00 -8.40364386e-01 -1.41927526e+00 -1.94638266e+00\n",
      " -1.26172775e+00  1.10777537e+00 -1.61103704e+00 -1.82394694e+00\n",
      " -1.10626064e+00 -1.63217393e+00 -8.26277278e-01 -1.14785718e+00\n",
      " -1.41968793e+00 -9.49363967e-01 -1.23773603e+00 -1.07608138e+00\n",
      " -1.60911897e+00 -1.81334513e+00 -1.48792764e+00 -8.03254598e-01\n",
      "  1.17074431e+00 -1.74782954e+00 -6.60734455e-01 -1.36476534e+00\n",
      " -9.67874161e-01 -1.37600635e+00 -1.11782136e+00 -1.78768921e+00\n",
      " -1.58650078e+00 -7.66264377e-01 -9.73434993e-01 -1.26445912e+00\n",
      " -2.01141016e+00 -4.69008349e-01 -6.35088699e-01 -1.70399710e+00\n",
      " -1.53967385e+00 -1.29295799e+00 -1.55281839e+00 -1.32105617e+00\n",
      " -3.93031752e-01 -1.06396539e+00 -1.56931391e+00 -1.30181578e+00\n",
      " -1.34649400e+00 -1.36516117e+00 -9.17503676e-01 -1.65000145e+00\n",
      " -1.07529355e+00 -1.72839583e+00 -1.37837848e+00 -1.22946637e+00\n",
      " -1.35357077e+00 -1.33332802e+00 -1.69587502e+00 -1.06197447e+00\n",
      " -1.22434746e+00 -1.03895254e+00  2.22739422e+00 -1.32712422e+00\n",
      " -1.81111927e+00 -1.52786710e+00 -1.74952344e+00 -1.42277287e+00\n",
      " -1.66128180e+00 -1.19279950e+00 -1.99625646e+00 -1.52186243e+00\n",
      " -2.19360070e+00 -1.94750124e+00 -3.24038326e-01 -9.94858976e-01\n",
      " -1.25725056e+00 -2.08434583e+00 -1.91244061e+00 -9.77866970e-01\n",
      " -1.43916053e+00 -1.04460320e+00 -1.13619841e+00 -2.20397758e-01\n",
      " -1.85626174e+00 -5.19888055e-01 -1.25708759e+00 -1.20290198e+00\n",
      " -1.13869533e+00 -1.11486713e+00 -1.00940116e+00 -1.37059530e+00\n",
      " -1.38243612e+00 -1.28328697e+00 -1.05652653e+00 -1.23105552e+00\n",
      " -1.32564373e+00  3.45566480e+00 -1.75432793e+00 -1.37831311e+00\n",
      " -9.63923947e-01 -1.49508165e+00 -1.59371573e+00 -1.21628138e+00\n",
      " -1.06495677e+00 -1.39164021e+00 -1.37735412e+00 -1.71226333e+00\n",
      " -1.32573969e+00 -1.32322148e+00 -1.43352340e+00 -2.00557430e+00\n",
      " -3.19817448e-01 -1.08713641e+00 -8.47599252e-01 -1.81063183e+00\n",
      " -7.43903324e-01 -1.21205535e+00 -1.17109066e+00 -2.09497799e+00\n",
      "  8.88377164e-01 -2.01063314e+00 -9.62295179e-01 -1.64598681e+00\n",
      " -1.03724222e+00 -1.18782788e+00 -1.27491056e+00 -8.33167470e-01\n",
      " -1.34639625e+00 -1.46808435e+00 -1.36281929e+00 -8.45725260e-01\n",
      " -8.10089519e-01 -1.59391213e+00 -1.29321306e+00 -1.51854672e+00\n",
      " -2.24432775e+00 -1.13400461e+00 -1.19870963e+00 -1.27714380e+00\n",
      " -1.47412975e+00 -1.69886000e+00 -5.66691044e-01 -1.81737840e+00\n",
      " -9.70002040e-01 -1.14304565e+00 -1.54149201e+00 -1.02187136e+00\n",
      " -9.38267813e-01 -8.15239083e-01 -1.59564299e+00 -1.33101678e+00\n",
      " -1.11434097e+00 -1.11195503e+00 -1.38460698e+00 -6.47392653e-01\n",
      " -1.58888482e+00 -1.50551193e+00 -1.31120793e+00 -1.47215758e+00\n",
      " -1.75125803e+00 -8.26845126e-01 -1.19513961e+00 -1.23072004e+00\n",
      " -1.16837168e+00 -1.50579895e+00 -1.64484229e+00 -9.81734700e-01\n",
      " -1.23857618e+00 -1.53524401e+00 -9.56491150e-01 -1.53948025e+00\n",
      " -1.70772342e+00 -1.59151765e+00 -1.10774100e+00 -1.10037405e+00\n",
      " -1.86707999e+00 -1.35815317e+00 -1.15008051e-01 -1.62843434e+00\n",
      " -1.25403851e+00 -1.73967062e+00 -3.34003726e-01 -9.25886980e-01\n",
      " -1.09707210e+00 -1.73460200e-01 -1.12305659e+00 -2.09459737e+00\n",
      " -1.28822860e+00 -1.17460075e+00 -1.48443269e+00 -1.30662483e+00\n",
      " -1.21880800e+00 -1.37736219e+00 -9.84285783e-01 -1.20243051e+00\n",
      " -1.38190923e+00 -1.34077155e+00 -3.84831934e-01 -1.96629178e+00\n",
      " -9.53446191e-01 -1.25957846e+00 -7.35621949e-01 -1.48133514e+00\n",
      " -2.02738140e+00 -1.57276094e+00 -8.01786364e-01 -1.65313075e+00\n",
      " -2.08959496e+00 -1.01311106e+00 -1.20285743e+00 -1.44839160e+00\n",
      " -1.13564851e+00  9.24587134e-03 -8.01141529e-01 -1.22348224e+00\n",
      " -1.23309031e+00 -1.10865073e+00 -1.43970873e+00 -1.14682173e+00\n",
      " -1.31278055e+00 -2.02927626e+00 -1.52238893e+00 -1.45490794e+00\n",
      " -1.43494426e+00 -1.44815956e+00 -1.99532132e+00 -1.68471637e+00\n",
      " -1.03399894e+00 -1.20029897e+00 -1.26876533e+00 -1.03704348e+00\n",
      "  5.79984209e-02 -1.51773716e+00  4.72082382e+00 -1.32383908e+00\n",
      " -1.00365100e+00  4.57032334e-01 -1.26490392e+00 -1.20325595e+00\n",
      " -1.40704184e+00 -9.97603931e-01 -1.14864717e+00  1.14152267e+00\n",
      " -1.15405621e+00 -1.01621585e+00  1.53718300e-01 -1.41173453e+00\n",
      " -1.57486699e+00 -1.74668960e+00 -9.19589143e-01 -4.71487058e-01\n",
      " -9.87947557e-01 -9.64850080e-01 -9.73531443e-01  1.75872805e+00\n",
      " -1.28667418e+00 -1.64496475e+00 -9.79375160e-01 -1.58395634e-01\n",
      " -1.11771121e+00 -1.32557618e+00 -1.30137832e+00 -1.34281434e+00\n",
      " -1.72017385e+00 -8.92721211e-01 -1.03164648e+00 -1.47770039e+00\n",
      " -1.17631692e+00 -1.00517916e+00 -1.97781741e+00 -1.34089978e+00\n",
      " -2.08157128e+00 -1.11227648e+00 -7.76210656e-01 -1.51667638e+00\n",
      "  4.52631816e-01 -1.17209965e+00 -9.79783586e-02 -1.20598672e+00\n",
      " -1.26617469e+00 -1.60558074e+00 -1.26770387e+00 -2.17652756e+00\n",
      " -2.38216938e+00 -9.91619759e-01 -9.39652852e-01 -1.27277144e+00\n",
      " -9.69098306e-01 -1.46707014e+00 -1.00455648e+00 -7.04881018e-01\n",
      " -1.75276170e+00 -1.28790871e+00 -5.01118118e-01 -1.35041984e+00\n",
      " -9.07657116e-01 -1.32644572e+00 -1.36463701e+00 -9.78683030e-01\n",
      " -1.25984041e+00 -2.34902216e+00 -1.05051291e+00 -1.12108909e+00\n",
      " -1.53351955e+00 -1.79806895e+00 -9.96858535e-01 -1.37541079e+00\n",
      " -1.28972115e+00 -1.06390128e+00 -1.16376789e+00 -8.59663564e-01\n",
      " -8.70981019e-01 -1.24316518e+00 -1.56162309e+00 -1.29079982e+00\n",
      " -4.03507394e-01 -1.58254034e+00 -1.01186686e+00 -1.96436261e+00\n",
      " -9.84529581e-01 -1.52047180e+00 -1.15312669e+00 -1.84055685e+00\n",
      " -1.17985095e+00 -1.48184730e+00 -1.16842341e+00 -9.03797616e-01\n",
      " -1.06050755e+00 -6.52553689e-01 -6.85068788e-01 -1.90764229e+00\n",
      " -1.45387811e+00 -1.66839945e+00 -2.42074085e+00 -5.17293026e-01\n",
      " -1.44255275e+00 -7.40812312e-01 -7.50912794e-01 -2.13238355e+00\n",
      "  9.87268731e-02 -1.14009529e+00 -1.50565928e+00 -1.63085587e+00\n",
      " -1.52145937e+00  5.26637369e-01 -9.34747053e-01 -9.25277732e-01\n",
      " -1.57234282e+00  1.19224068e+00 -1.00403868e+00 -1.12622173e+00\n",
      " -9.23027427e-01 -1.41569303e+00 -9.44347082e-02 -3.69529163e-01\n",
      " -9.78203821e-01 -1.08259059e+00 -9.78914705e-01 -1.19051971e+00\n",
      " -1.44164053e+00 -1.03644916e+00 -8.57009262e-01 -1.57860166e+00\n",
      " -1.72441709e+00 -1.01115422e+00  2.58206450e+00 -1.35902811e+00\n",
      " -1.30541949e+00 -1.55241685e+00 -1.40941642e+00 -1.29272676e+00\n",
      " -1.37835526e+00 -1.68390502e+00 -1.44175473e+00 -8.22194769e-01\n",
      " -1.77560832e+00 -1.25353944e+00 -1.30889057e+00 -8.76303451e-01\n",
      " -9.73016220e-01 -1.61460649e+00 -1.23043815e+00 -1.19026986e+00\n",
      " -1.24725297e+00 -1.43667776e+00 -1.62511154e+00 -1.88189372e+00\n",
      " -8.68530827e-01 -9.68484247e-01 -1.83046809e+00 -1.71708191e+00\n",
      " -1.53096699e+00 -1.40558608e+00 -6.40790867e-01 -1.02365544e+00\n",
      " -8.28256686e-01 -1.11148234e+00 -1.15168456e+00  3.20409588e+00\n",
      " -1.10072941e+00 -1.13768645e+00  6.83262616e-01 -1.32052849e+00\n",
      " -1.57020624e+00 -1.18932881e+00  7.67788440e-01 -1.66583132e+00\n",
      " -1.30865284e+00 -1.04022340e+00 -9.68296776e-01 -1.09211472e+00\n",
      " -2.11646204e+00 -1.37265000e+00 -1.60686834e+00 -1.24704965e+00\n",
      " -2.99692995e-01 -1.28389040e+00 -1.67931292e+00 -1.25256217e+00\n",
      " -1.10489041e+00 -8.96151565e-01 -1.51221598e+00 -1.51276788e+00\n",
      " -8.04114920e-01 -6.59363875e-01 -4.32775465e-01 -8.79267542e-01\n",
      " -1.37235103e+00 -1.11270523e+00 -1.80628814e+00 -9.09855606e-01\n",
      " -1.51718026e+00 -7.67586221e-01 -1.55032509e+00 -1.02017631e+00\n",
      " -1.47297666e+00 -1.29108927e+00 -1.32994950e+00 -9.68378878e-01\n",
      " -1.07854291e+00 -9.53228904e-01 -1.36888041e+00 -5.94925715e-01\n",
      " -1.07340792e+00 -1.49899278e+00 -1.44111244e+00 -1.82156579e+00\n",
      " -1.71612295e+00 -1.43639621e+00 -1.25525561e+00 -7.13496015e-01\n",
      " -1.38585233e+00 -1.54851850e+00 -1.35871380e+00 -8.58899716e-01\n",
      " -1.05225483e+00 -1.26486406e+00 -1.32267502e+00 -1.76980934e+00\n",
      " -8.60699139e-01 -6.37861370e-01 -1.24543252e+00 -1.17991760e+00\n",
      " -2.12633683e+00  1.19345205e+00 -1.35137944e+00 -1.64221627e+00\n",
      " -1.51086762e+00  2.46518341e-01 -1.72347840e+00 -1.16197620e+00\n",
      " -9.06060187e-01 -1.34847349e+00 -2.14051249e+00 -1.20431738e+00\n",
      " -2.05495818e-01 -1.16704299e+00 -2.06997470e+00 -1.24904816e+00\n",
      " -7.69479756e-01 -2.23238889e+00 -5.10006080e-01 -2.06493055e+00\n",
      " -1.48375376e+00 -1.58376986e+00 -1.62016662e+00 -8.11458014e-01\n",
      " -1.66638205e+00 -1.35974328e+00 -1.66055954e+00 -1.93003295e+00\n",
      " -1.23753552e+00 -3.53254461e-01 -1.43032539e+00 -1.39437103e+00\n",
      " -1.25601580e+00 -2.44433391e-01 -1.46659269e+00 -7.66584406e-01\n",
      " -1.47965828e+00 -1.20169242e+00 -1.90179226e+00  1.63267888e+00\n",
      " -1.24484489e+00 -1.55860276e+00 -1.38900975e+00 -1.05090409e+00\n",
      " -1.70614405e+00 -1.52505358e+00 -1.01189803e+00 -7.90815270e-01\n",
      " -1.47658421e+00 -1.73669664e+00 -1.10703103e+00  5.56824127e-01\n",
      " -1.35501985e+00 -1.36159274e+00 -1.21270660e+00  2.37919552e-01\n",
      " -1.44080751e+00 -1.05512219e+00  1.76234860e+00 -1.16602670e+00\n",
      " -2.16021978e-02 -1.35392095e+00 -1.59918867e+00 -1.27583511e+00\n",
      " -1.18045389e+00 -9.48319017e-01 -9.01103708e-01 -1.66172944e+00\n",
      " -1.17089338e+00 -1.27576619e+00 -1.54198463e+00 -1.45205554e+00\n",
      " -1.68580595e+00 -8.77747843e-01 -1.34575882e+00 -1.65123776e+00\n",
      " -9.78047441e-01 -1.06090359e+00 -1.74790691e+00 -1.51535485e+00\n",
      " -1.55008213e+00 -4.66779280e-01 -1.20365532e+00 -1.46344553e+00\n",
      " -2.07801703e+00 -1.46752899e+00 -9.03248022e-01 -1.21887909e+00\n",
      " -1.37959162e+00 -1.31408239e+00  6.82513878e-02 -2.29286459e+00\n",
      " -6.03960811e-01 -1.34200325e+00 -1.31125993e+00 -1.36451568e+00\n",
      " -6.67470986e-01 -9.56618412e-01 -1.32134728e+00 -1.50143841e+00\n",
      " -4.91691426e-01 -1.80731489e+00 -1.25443992e+00 -1.72552505e+00\n",
      " -4.59836343e-01 -1.80331738e+00 -1.58772173e+00 -1.08696322e+00\n",
      " -1.30029820e+00 -7.95161217e-01 -1.11442360e+00 -1.09103811e+00\n",
      " -1.58582339e+00 -1.41832348e+00 -1.03055393e+00 -1.41403705e+00\n",
      " -1.44983845e+00 -1.41089173e+00 -3.25981658e-01 -1.43830670e+00\n",
      " -1.08968891e+00 -1.09648860e+00 -6.08467693e-01 -1.42123695e+00\n",
      " -1.42283806e+00 -1.34802555e+00 -8.43830585e-01 -1.16955794e+00\n",
      " -9.94583514e-01 -1.39056719e+00 -8.61960712e-01 -8.89643640e-01\n",
      " -1.64362874e+00 -1.30487818e+00 -1.19270404e+00 -9.51220272e-01\n",
      " -1.45240277e+00 -1.21682374e+00 -1.25051371e+00 -1.30992731e+00\n",
      " -1.35122525e+00 -1.75557918e+00 -1.07846753e+00 -1.22714761e+00\n",
      " -1.53451276e+00  3.26166496e-01 -1.71802512e+00 -1.25581916e+00\n",
      " -1.34946018e+00 -1.04097413e+00 -3.97002080e-01  3.98236608e+00\n",
      " -1.20345219e+00 -2.00217190e+00 -1.37994387e+00 -4.06069758e-01\n",
      " -1.94344890e+00 -1.42619285e+00 -9.34521213e-01 -1.36239851e+00\n",
      " -1.23393404e+00 -1.49551779e+00 -1.35082200e+00 -1.00301517e+00\n",
      " -1.19883807e+00  6.52553810e-01 -4.98014488e-03 -2.31865212e+00\n",
      " -1.46874224e+00  3.46508255e+00 -1.19154856e+00 -3.28803329e-01\n",
      " -1.61288847e+00 -1.20270288e+00 -1.01703353e+00 -1.15824115e+00\n",
      " -1.68351483e+00 -1.49141930e+00 -1.52471915e+00 -1.21318709e+00\n",
      " -1.46556696e+00 -1.22953976e+00 -1.88303802e+00 -1.08575143e+00\n",
      " -1.58452740e+00 -9.49087939e-01 -1.75085648e+00 -1.66882091e+00\n",
      " -1.34971965e+00 -1.35898902e+00 -1.40108817e+00 -1.09068864e+00\n",
      " -7.80567676e-01 -8.65732563e-01 -8.33311808e-01 -1.09910100e+00\n",
      " -1.46123053e+00 -1.29656857e+00 -1.19617935e+00 -1.22701209e+00\n",
      " -9.96789334e-01 -1.33702147e+00 -1.05611582e+00 -1.01141750e+00\n",
      " -1.44683038e+00 -1.33997716e+00 -8.22985100e-01 -1.15934765e+00\n",
      " -1.27008562e+00 -1.48985031e+00 -1.26446124e+00 -1.56624796e+00\n",
      " -1.10586564e+00 -1.18052388e+00 -7.31500979e-01 -1.21002461e+00\n",
      "  2.47161535e+00 -1.33030063e+00 -1.16161155e+00 -1.20849136e+00\n",
      "  4.54081181e-02 -1.32574023e+00 -1.07224182e+00 -1.41650472e+00\n",
      " -1.34502055e+00 -1.02774770e+00 -2.68651968e-01 -1.47019751e+00\n",
      " -1.45546048e+00 -9.65655639e-01 -1.61871333e-02 -1.26595984e+00\n",
      " -1.24158678e+00 -1.06236063e+00 -1.22778948e+00 -1.83638332e+00\n",
      " -1.30498966e+00 -1.84592525e+00 -1.45636464e+00 -1.36329639e+00\n",
      " -1.41531814e+00  1.92304391e+00 -1.29543172e+00 -1.24139271e+00\n",
      " -1.55871608e+00 -8.93571870e-01 -1.39885675e+00 -1.15922561e+00\n",
      " -1.23232536e+00 -1.83523676e+00 -1.51510921e+00 -1.37160761e+00\n",
      " -1.71453920e+00 -1.02062939e+00 -1.48235230e+00 -1.44664566e+00\n",
      " -1.18858929e+00 -1.29963035e+00 -1.06079602e+00 -1.30536219e+00\n",
      " -1.02412115e+00 -1.46545900e+00 -9.26635967e-01 -1.06940676e+00\n",
      " -1.27042318e+00 -1.65137678e+00 -1.47012616e+00 -1.50982738e+00\n",
      " -1.65923610e+00 -8.53371518e-01 -1.77682273e+00 -1.02528009e+00\n",
      " -5.92034020e-01 -7.50138582e-01 -1.55842252e+00 -1.71755608e+00\n",
      " -1.61978094e+00 -1.05404572e+00 -1.15506591e+00 -9.62243760e-01\n",
      " -1.09284642e+00 -1.22670792e+00 -1.11727036e+00 -1.73204090e-02\n",
      " -2.08114869e+00 -1.20704309e+00 -9.79266396e-01 -6.94307559e-01\n",
      " -1.13428990e+00 -1.31354686e+00 -1.30835930e+00 -1.68166893e+00\n",
      " -1.36698511e+00 -1.28859546e+00 -1.51283119e+00 -1.31993508e+00\n",
      " -1.78903630e+00 -1.36547675e+00 -1.34453407e+00 -9.79126189e-01\n",
      "  1.97393124e+00  3.28020823e-01  1.46409970e+00 -1.90370000e+00\n",
      " -1.59346194e+00 -1.88803948e+00 -1.19742208e+00 -1.22739363e+00\n",
      " -1.25991551e+00 -1.39543029e+00 -5.57128094e-01 -1.66166801e+00\n",
      "  2.39846380e+00 -1.24265187e+00 -1.86322438e+00 -2.15211206e+00\n",
      " -1.42092311e+00 -1.09213557e+00 -1.62376021e+00 -1.27789817e+00\n",
      " -1.69721681e+00 -1.58908693e+00 -1.50367519e+00 -1.73752651e+00]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "score1 = model1.decision_function(X_test)\n",
    "print(score1)\n",
    "print(yhat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that the decision function output represents whether a predicted sample for x_test by the classifier lies to the right side or left side of hyperplane and also how far from it. It also tells us how confidently each value predicted for x_test by the classifier is Positive ( large-magnitude Positive value ) or Negative ( large-magnitude Negative value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "score2 = model2.predict_proba(X_test)\n",
    "print(score2[1:7])\n",
    "print(yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.90909091 0.09090909]\n",
      " [1.         0.        ]\n",
      " [0.81818182 0.18181818]\n",
      " [0.27272727 0.72727273]\n",
      " [0.90909091 0.09090909]\n",
      " [1.         0.        ]]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "score3 = model3.predict_proba(X_test)\n",
    "print(score3[1:7])\n",
    "print(yhat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9777936  0.0222064 ]\n",
      " [0.79377345 0.20622655]\n",
      " [0.8463381  0.1536619 ]\n",
      " [0.7456534  0.2543466 ]\n",
      " [0.70816326 0.29183674]\n",
      " [0.84299633 0.15700367]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "score4 = model4.predict_proba(X_test)\n",
    "print(score4[1:7])\n",
    "print(yhat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1\n",
      " 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 0 0 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(yhat2)\n",
    "print(yhat3)\n",
    "print(yhat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled=scaler.fit_transform(X_train)\n",
    "    \n",
    "model1.fit(X_train_scaled,y_train)\n",
    "model2.fit(X_train_scaled,y_train)\n",
    "model3.fit(X_train_scaled,y_train)\n",
    "model4.fit(X_train_scaled,y_train)\n",
    "\n",
    "\n",
    "yhat1_scaled = model1.predict(X_test)\n",
    "yhat2_scaled = model2.predict(X_test)\n",
    "yhat3_scaled = model3.predict(X_test)\n",
    "yhat4_scaled = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.89224136 -0.91577423 -0.91491795 -0.89169013 -0.91364272 -0.8892205\n",
      " -0.89520461 -0.90058941 -0.90825035 -0.89043498 -0.90097654 -0.91003674\n",
      " -0.89899292 -0.90246921 -0.8879494  -0.89556277 -0.91053972 -0.90814373\n",
      " -0.89609825 -0.89646431 -0.9068256  -0.89391089 -0.9146675  -0.89755143\n",
      " -0.91312525 -0.90817982 -0.91427544 -0.89802062 -0.91216677 -0.90255245\n",
      " -0.89919875 -0.91740344 -0.88482489 -0.90864051 -0.91407689 -0.89022035\n",
      " -0.89711842 -0.91470425 -0.92274111 -0.89323594 -0.9083724  -0.90309252\n",
      " -0.89849584 -0.90330058 -0.91053419 -0.91355282 -0.89000878 -0.88893196\n",
      " -0.90511324 -0.90021074 -0.90731765 -0.89490916 -0.89998831 -0.91220888\n",
      " -0.90129129 -0.90946252 -0.9115186  -0.91713352 -0.89864703 -0.89624955\n",
      " -0.90217107 -0.920149   -0.91342662 -0.90289675 -0.90190787 -0.89852118\n",
      " -0.91091098 -0.90130655 -0.91598317 -0.89816157 -0.91594411 -0.91771131\n",
      " -0.90330813 -0.9025104  -0.90888999 -0.89787739 -0.89598311 -0.90769448\n",
      " -0.906494   -0.91664477 -0.89634589 -0.90081016 -0.89350329 -0.89107894\n",
      " -0.89337549 -0.89354294 -0.9072605  -0.89461535 -0.91414968 -0.90980002\n",
      " -0.90988339 -0.9033638  -0.91330804 -0.90452181 -0.90118339 -0.90346997\n",
      " -0.9152634  -0.89433463 -0.89653169 -0.90938343 -0.90097776 -0.89863978\n",
      " -0.90322488 -0.89777014 -0.91225366 -0.91317798 -0.89100122 -0.89242936\n",
      " -0.89793137 -0.90846389 -0.91254431 -0.91747511 -0.89172882 -0.91267973\n",
      " -0.91247054 -0.91285945 -0.91363744 -0.913942   -0.91364189 -0.88911867\n",
      " -0.90235211 -0.90898808 -0.90409486 -0.90682419 -0.90173367 -0.91674049\n",
      " -0.9207543  -0.89992514 -0.91830051 -0.90022444 -0.9115268  -0.9113811\n",
      " -0.8988495  -0.88664364 -0.90535122 -0.89982244 -0.88692382 -0.90514659\n",
      " -0.90234442 -0.88659327 -0.90808485 -0.89904306 -0.89470812 -0.89539812\n",
      " -0.89663556 -0.90450485 -0.90763252 -0.90915637 -0.90962866 -0.90073034\n",
      " -0.89538233 -0.90262247 -0.9045315  -0.88911191 -0.90391884 -0.90103108\n",
      " -0.88747926 -0.91071015 -0.90539805 -0.91732725 -0.90530113 -0.91631094\n",
      " -0.90508991 -0.90067256 -0.89790125 -0.91708944 -0.89951569 -0.91312107\n",
      " -0.8963397  -0.90634917 -0.90091043 -0.90689945 -0.89237063 -0.92024954\n",
      " -0.91373166 -0.91063531 -0.89968805 -0.90109203 -0.8996471  -0.89777165\n",
      " -0.89811825 -0.91830129 -0.90885956 -0.9113729  -0.91750476 -0.91000676\n",
      " -0.91004991 -0.9108389  -0.90922897 -0.9064503  -0.90423296 -0.90364839\n",
      " -0.90574342 -0.9089769  -0.9165235  -0.89795319 -0.91563167 -0.91826452\n",
      " -0.89431096 -0.90488112 -0.90104497 -0.90125225 -0.91933983 -0.91980275\n",
      " -0.913198   -0.91371359 -0.90596085 -0.89240584 -0.91156038 -0.90494823\n",
      " -0.9091908  -0.90704909 -0.89901954 -0.90378295 -0.90618576 -0.89612467\n",
      " -0.90522738 -0.91371266 -0.90783764 -0.91540609 -0.89340654 -0.89871941\n",
      " -0.90392378 -0.91168322 -0.91292293 -0.90312061 -0.91333426 -0.89618382\n",
      " -0.90743562 -0.91637472 -0.91633437 -0.89986873 -0.91114619 -0.90973297\n",
      " -0.89543083 -0.91034355 -0.90332828 -0.89305048 -0.9026604  -0.91604016\n",
      " -0.90482716 -0.90719392 -0.91490045 -0.9081394  -0.9134338  -0.89637585\n",
      " -0.88875182 -0.90965426 -0.88289144 -0.9126455  -0.91869913 -0.91003118\n",
      " -0.91413261 -0.90236376 -0.91732853 -0.91781269 -0.91519943 -0.89353709\n",
      " -0.90777096 -0.91480357 -0.89490361 -0.91432235 -0.90764431 -0.91849603\n",
      " -0.91846568 -0.90994122 -0.89647303 -0.90445632 -0.89800399 -0.91570325\n",
      " -0.89637462 -0.91433327 -0.91418763 -0.89645243 -0.91335073 -0.91554045\n",
      " -0.91406846 -0.90173616 -0.88512938 -0.89348008 -0.91829685 -0.90189538\n",
      " -0.90742659 -0.90986266 -0.91630163 -0.88289085 -0.91889726 -0.92432054\n",
      " -0.89678353 -0.89649825 -0.90931015 -0.91424971 -0.89930253 -0.9112923\n",
      " -0.89788583 -0.89241676 -0.88273365 -0.91317365 -0.91529547 -0.9146017\n",
      " -0.89127849 -0.90408015 -0.90717467 -0.91416189 -0.91383356 -0.91819594\n",
      " -0.91730849 -0.90820622 -0.91844761 -0.89574489 -0.89590299 -0.89564758\n",
      " -0.91666113 -0.89916781 -0.91730355 -0.89165465 -0.89993328 -0.91225525\n",
      " -0.90813188 -0.92180574 -0.91198481 -0.90803341 -0.90560673 -0.89605115\n",
      " -0.90634289 -0.90202808 -0.91357989 -0.90643983 -0.9078791  -0.91493919\n",
      " -0.89502318 -0.91714494 -0.90377947 -0.91622386 -0.89998358 -0.92344633\n",
      " -0.90717311 -0.91673935 -0.90993886 -0.90627304 -0.91428219 -0.89916373\n",
      " -0.8947028  -0.90457119 -0.91508755 -0.91588329 -0.90098163 -0.91140405\n",
      " -0.90590148 -0.9152061  -0.9080651  -0.9026888  -0.89023708 -0.90692571\n",
      " -0.89428094 -0.89718996 -0.91230083 -0.89164558 -0.90610437 -0.91699228\n",
      " -0.89901081 -0.91103471 -0.89205426 -0.8977048  -0.90449097 -0.90678923\n",
      " -0.88257029 -0.90521397 -0.90342353 -0.91395313 -0.9138796  -0.89884287\n",
      " -0.89782174 -0.91542169 -0.90437994 -0.90186823 -0.90267455 -0.91218065\n",
      " -0.90758608 -0.89451736 -0.89196168 -0.89915718 -0.89644955 -0.90804155\n",
      " -0.91554968 -0.90262798 -0.91512501 -0.91328673 -0.90125283 -0.91869435\n",
      " -0.91274563 -0.90251023 -0.9120514  -0.9099147  -0.89298954 -0.90799517\n",
      " -0.90967213 -0.90344488 -0.9183999  -0.891416   -0.90996061 -0.8934394\n",
      " -0.89395027 -0.90255802 -0.9092799  -0.90466732 -0.89365407 -0.89355834\n",
      " -0.90553788 -0.89952496 -0.89675876 -0.89936717 -0.90841527 -0.91686051\n",
      " -0.88786788 -0.91722462 -0.90772882 -0.90176684 -0.89885315 -0.89240068\n",
      " -0.89466943 -0.91435682 -0.90440998 -0.89958676 -0.91003677 -0.92570987\n",
      " -0.9153781  -0.89106138 -0.9136888  -0.90387268 -0.89869307 -0.90866905\n",
      " -0.89294082 -0.91789307 -0.90567693 -0.90374928 -0.90288048 -0.89585604\n",
      " -0.89973574 -0.90892983 -0.91489274 -0.89922261 -0.87925648 -0.90388994\n",
      " -0.89801445 -0.90359554 -0.91752494 -0.9017916  -0.90057504 -0.89966163\n",
      " -0.89982504 -0.89531025 -0.89636566 -0.90066448 -0.90967873 -0.91345654\n",
      " -0.9187232  -0.90397161 -0.89842026 -0.90326005 -0.89847922 -0.91069729\n",
      " -0.90567713 -0.9063124  -0.91272738 -0.89202002 -0.89965076 -0.8970987\n",
      " -0.89946608 -0.92227373 -0.92192993 -0.90316256 -0.90023969 -0.89357061\n",
      " -0.91002155 -0.90423385 -0.91583669 -0.90240773 -0.90896453 -0.89197294\n",
      " -0.89580247 -0.91540202 -0.9168341  -0.91130131 -0.90211542 -0.92030006\n",
      " -0.91269412 -0.9167747  -0.90576192 -0.91324513 -0.91328226 -0.89038438\n",
      " -0.89949317 -0.90770947 -0.91625241 -0.91505558 -0.90086396 -0.89900774\n",
      " -0.90749851 -0.89291805 -0.90651769 -0.90650343 -0.9003446  -0.90105811\n",
      " -0.90738206 -0.89418213 -0.89244789 -0.8867292  -0.89930059 -0.90288771\n",
      " -0.91453521 -0.90632552 -0.90715496 -0.90387962 -0.90162696 -0.90475422\n",
      " -0.89963869 -0.90231984 -0.90389074 -0.89367307 -0.89705124 -0.9097829\n",
      " -0.90192927 -0.91352683 -0.90164516 -0.9008772  -0.88843524 -0.91670011\n",
      " -0.89835941 -0.89618264 -0.918067   -0.90388683 -0.91873519 -0.88556282\n",
      " -0.90028517 -0.8931806  -0.90808689 -0.8960702  -0.90800607 -0.91671522\n",
      " -0.91521853 -0.89901289 -0.90553839 -0.90841487 -0.89119984 -0.90192127\n",
      " -0.90460738 -0.90776491 -0.89977613 -0.9056604  -0.90095894 -0.92526475\n",
      " -0.89979221 -0.90203495 -0.91169635 -0.91045778 -0.89977033 -0.89917534\n",
      " -0.89860521 -0.9134578  -0.91410778 -0.89818229 -0.90003959 -0.90442573\n",
      " -0.90833427 -0.90404009 -0.91987994 -0.89995531 -0.91928201 -0.89196387\n",
      " -0.91310577 -0.91206636 -0.88841398 -0.91226964 -0.89281482 -0.90907332\n",
      " -0.89903814 -0.91696878 -0.91655862 -0.8928869  -0.88808491 -0.89721778\n",
      " -0.90171386 -0.91747375 -0.90002845 -0.91029282 -0.91387647 -0.91442034\n",
      " -0.89109451 -0.90885555 -0.90357065 -0.89335455 -0.90039974 -0.88286017\n",
      " -0.88843718 -0.90497575 -0.90196799 -0.88988966 -0.88882301 -0.91780061\n",
      " -0.9029913  -0.9047628  -0.91506023 -0.91233677 -0.90076863 -0.90317431\n",
      " -0.89769985 -0.90284488 -0.91265023 -0.89242124 -0.91322288 -0.90519097\n",
      " -0.91943878 -0.90872351 -0.91091638 -0.90389028 -0.9016644  -0.90830302\n",
      " -0.89124229 -0.91237288 -0.89436972 -0.8929156  -0.90465531 -0.8981162\n",
      " -0.8869597  -0.89446153 -0.9060265  -0.90268621 -0.90056083 -0.90444568\n",
      " -0.91719191 -0.91715058 -0.90305617 -0.88758205 -0.90599397 -0.91380116\n",
      " -0.91241039 -0.91233096 -0.89201014 -0.89914569 -0.88932944 -0.9146769\n",
      " -0.89809058 -0.91427846 -0.91229112 -0.91580652 -0.89133171 -0.91300174\n",
      " -0.89572313 -0.90830269 -0.91195538 -0.91463667 -0.89165942 -0.91226167\n",
      " -0.91423563 -0.8979551  -0.91468324 -0.88513836 -0.8958293  -0.90483296\n",
      " -0.90364363 -0.90154993 -0.90266194 -0.90377213 -0.90407123 -0.91163008\n",
      " -0.88532883 -0.89224266 -0.89379597 -0.890549   -0.89248163 -0.91383561\n",
      " -0.89601786 -0.91478546 -0.89967994 -0.89755113 -0.91140664 -0.88454131\n",
      " -0.90341362 -0.90784531 -0.90085511 -0.91224713 -0.89607607 -0.91319887\n",
      " -0.88625074 -0.8988052  -0.89407541 -0.89845159 -0.89406206 -0.91164851\n",
      " -0.90692529 -0.89977582 -0.90283979 -0.89028115 -0.89823028 -0.90393045\n",
      " -0.90848206 -0.90800532 -0.90725972 -0.91591735 -0.9170755  -0.90958296\n",
      " -0.89806521 -0.89659608 -0.90942019 -0.91430973 -0.88780674 -0.91136837\n",
      " -0.8933193  -0.90498771 -0.891042   -0.90212093 -0.89102903 -0.90820609\n",
      " -0.89965838 -0.90020889 -0.89540242 -0.92358449 -0.91603351 -0.91600495\n",
      " -0.89667115 -0.89538279 -0.9173803  -0.89394644 -0.90368166 -0.89552709\n",
      " -0.91341078 -0.90641461 -0.90995479 -0.89876822 -0.90431273 -0.9072982\n",
      " -0.90124413 -0.91253755 -0.90043645 -0.91432781 -0.90684821 -0.90236988\n",
      " -0.90052623 -0.90850315 -0.90600524 -0.90496948 -0.90852449 -0.91488649\n",
      " -0.91641174 -0.89489908 -0.88694042 -0.90762758 -0.89358751 -0.88973706\n",
      " -0.89242648 -0.90246487 -0.90535316 -0.90151954 -0.90701468 -0.91982341\n",
      " -0.9101569  -0.915575   -0.90154676 -0.89426751 -0.88817893 -0.91074837\n",
      " -0.91990581 -0.89812653 -0.89239245 -0.8947605  -0.91241204 -0.89970483\n",
      " -0.92012618 -0.8894581  -0.89290261 -0.9169242  -0.91188813 -0.91148397\n",
      " -0.91403754 -0.89807351 -0.90364227 -0.89155149 -0.91378826 -0.9166984\n",
      " -0.90389945 -0.91333344 -0.91778479 -0.90287636 -0.90732139 -0.91057685\n",
      " -0.91977872 -0.90080763 -0.89782389 -0.91522514 -0.89708938 -0.90699111\n",
      " -0.90832811 -0.90975595 -0.89919286 -0.89430576 -0.89279047 -0.89547777\n",
      " -0.9145479  -0.89579945 -0.91343854 -0.90166144 -0.89943477 -0.91543768\n",
      " -0.89573118 -0.91196881 -0.91569889 -0.90352054 -0.91415429 -0.90099156\n",
      " -0.90695831 -0.92083052 -0.9128322  -0.89533735 -0.89078171 -0.89364562\n",
      " -0.90111666 -0.89608367 -0.90375155 -0.91752125 -0.91479233 -0.89139484\n",
      " -0.90075631 -0.91439971 -0.91981149 -0.90647117 -0.89418606 -0.91833421\n",
      " -0.90354725 -0.90326119 -0.90118735 -0.91415544 -0.88828959 -0.91072572\n",
      " -0.91100397 -0.91579369 -0.91932367 -0.90519808 -0.90859724 -0.89966023\n",
      " -0.89964336 -0.91475785 -0.90076464 -0.90679549 -0.89975548 -0.90273656\n",
      " -0.89916691 -0.91067086 -0.90244599 -0.90404605 -0.91324028 -0.90537042\n",
      " -0.91789262 -0.90181983 -0.89921501 -0.91101248 -0.92103673 -0.89221022\n",
      " -0.88386988 -0.89940831 -0.9047374  -0.90246024 -0.91745102 -0.9074264\n",
      " -0.918385   -0.90442993 -0.89223175 -0.91100422 -0.91491615 -0.9145053\n",
      " -0.90177023 -0.89666489 -0.88188593 -0.9059072  -0.91376583 -0.9072132\n",
      " -0.89837224 -0.89727895 -0.91178198 -0.91270684 -0.90626904 -0.90145114\n",
      " -0.91646456 -0.89159164 -0.89448988 -0.88947271 -0.89571915 -0.90734987\n",
      " -0.91479131 -0.91665464 -0.91655796 -0.91188886 -0.9146001  -0.90016786\n",
      " -0.90452281 -0.913335   -0.91431715 -0.89803663 -0.91089882 -0.91374407\n",
      " -0.90076274 -0.90609674 -0.89379398 -0.90572339 -0.88339131 -0.91412213\n",
      " -0.91132168 -0.90368206 -0.91361617 -0.89991056 -0.91666266 -0.89499232\n",
      " -0.89798226 -0.90630559 -0.91202056 -0.89568017 -0.89679949 -0.89174455\n",
      " -0.91432401 -0.91414614 -0.90634088 -0.91527804 -0.91684447 -0.90407453\n",
      " -0.91205499 -0.89900932 -0.89893477 -0.90759149 -0.91303607 -0.89700228\n",
      " -0.91131353 -0.89846418 -0.90460036 -0.91031722 -0.91333022 -0.9138961\n",
      " -0.90329908 -0.90076744 -0.88828205 -0.8998354  -0.90739617 -0.91981886\n",
      " -0.90939458 -0.89675626 -0.91606933 -0.88947518 -0.91595764 -0.90759027\n",
      " -0.9101504  -0.90369107 -0.91953315 -0.89992115 -0.8988071  -0.90640533\n",
      " -0.91654185 -0.89624001 -0.90010913 -0.90138915 -0.90122359 -0.89478181\n",
      " -0.90411585 -0.90900451 -0.90419598 -0.89179539 -0.9172212  -0.90614827\n",
      " -0.89641278 -0.91675481 -0.91332335 -0.9004666  -0.90557742 -0.9162036\n",
      " -0.9158635  -0.92122425 -0.92153297 -0.89625844 -0.89424223 -0.90132144\n",
      " -0.9009138  -0.91170582 -0.89878988 -0.88850076 -0.91208026 -0.91879751\n",
      " -0.91450713 -0.8926377  -0.90529851 -0.9050571  -0.90622435 -0.9092275\n",
      " -0.92170559 -0.90679046 -0.90637298 -0.90292392 -0.89094912 -0.91588913\n",
      " -0.9171263  -0.91476652 -0.90923555 -0.90076862]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "score1 = model1.decision_function(X_test)\n",
    "print(score1)\n",
    "print(yhat1_scaled)\n",
    "\n",
    "#score1 = model1.predict_proba(X_test)\n",
    "\n",
    "##decision_function\n",
    "\n",
    "#fpr1, tpr1,_ = metrics.roc_curve(y_test,score1[:,1])\n",
    "#fig = plt.figure()\n",
    "#plt.plot(fpr1,tpr1)\n",
    "#plt.plot(np.array(FPR)[idx],np.array(TPR)[idx],'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The price of confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us work out a little more the problem of `Churn?`, once again. Consider the following simple business case:\n",
    "\n",
    "We want to lauch a retention marketing campaing:\n",
    "\n",
    "+ Each member in the subscription service gives us a profit of $100$ units.\n",
    "+ The cost of the campaign is $\\alpha=10$ units per advertisement.\n",
    "+ Supose that we only recover $\\beta = 10\\%$ of the people that received the campaign and were going to churn.\n",
    "+ We are going to use a classifier to select the targets of the campaign.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class = \"alert alert-success\" style = \"border-radius:10px\">\n",
    "**EXERCISE/QUESTION:** Model the former problem in terms of the elements of the confusion matrix. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class = \"alert alert-success\" style = \"border-radius:10px\">\n",
    "**EXERCISE:** Train a `LogisticRegressor` and check if the campaign is profitable. Use `test_size = 0.3` and `random_state = 31`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = c[1,1]\n",
    "FP = c[1,0]\n",
    "TN = c[0,0]\n",
    "FN = c[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN_hand = np.sum(np.logical_and(yhat!=y_test,yhat==0.))\n",
    "\n",
    "print (FN,FN_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 10\n",
    "beta = 0.1\n",
    "balance=-alpha*(TP+FP)+beta*TP*100\n",
    "print (balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The campaign is not sustainable as it is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us choose an operating point, so that we maximize the validation profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lr.predict_proba(X_test)\n",
    "\n",
    "idx=np.argsort(score[:,1])\n",
    "\n",
    "balance_old = -1e10 \n",
    "max_idx  = 0\n",
    "b = []\n",
    "for i in idx:\n",
    "    yhat = np.where(score[:,1]>score[i,1],1.0,0.0)\n",
    "    TP = np.sum(np.logical_and(yhat==y_test,yhat==1.))\n",
    "    TN = np.sum(np.logical_and(yhat==y_test,yhat==0.))\n",
    "    FP = np.sum(np.logical_and(yhat!=y_test,yhat==1.))\n",
    "    FN = np.sum(np.logical_and(yhat!=y_test,yhat==0.))\n",
    "    alpha = 10\n",
    "    beta = 0.1\n",
    "    balance=-alpha*(TP+FP)+beta*TP*100\n",
    "    \n",
    "    b.append(balance)\n",
    "    \n",
    "    if balance > balance_old:\n",
    "        max_idx = i\n",
    "        balance_old = balance\n",
    "    \n",
    "plt.plot(np.array(b))\n",
    "score[max_idx,1]\n",
    "yhat = np.where(score[:,1]>score[max_idx,1],1.0,0.0)\n",
    "print (metrics.confusion_matrix(yhat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operating point indicates it is not worthwhile to consider a campaign with this kind of classifier. But can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dealing with unbalanced datasets\n",
    "\n",
    "The greatest problem we are facing is due to the fact we are dealing with unbalanced datasets and the original boundary just depends on that. We can try different things to balance the data set:\n",
    "\n",
    "+ Under sample the majority class.\n",
    "+ Over sample the minority class using some kind of data interpolator, for example SMOTE.\n",
    "+ Use class weights, this is also called cost-sensitive classification.\n",
    "+ Change the performance metric.\n",
    "+ Split the majority class in subclasses, then train as many classifiers as subclasses. Each involving one subclasses and the minority class. Then use an aggregation technique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us proceed checking some of these techniques. Let us start with resampling the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pidx = np.where(y_train == 1)[0]\n",
    "nidx = np.where(y_train == 0)[0]\n",
    "\n",
    "print (np.sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidx=np.random.randint(0,len(nidx),size=np.sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_idx =[]\n",
    "resampled_idx=np.r_[pidx,sidx]\n",
    "X_resampled=X_train[resampled_idx,:]\n",
    "y_resampled=y_train[resampled_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "lr = linear_model.LogisticRegression()\n",
    "\n",
    "lr.fit(X_resampled,y_resampled)\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "c = metrics.confusion_matrix(yhat,y_test)\n",
    "\n",
    "\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lr.predict_proba(X_test)\n",
    "\n",
    "idx=np.argsort(score[:,1])\n",
    "\n",
    "balance_old = -1e10 \n",
    "max_idx  = 0\n",
    "b = []\n",
    "for i in idx:\n",
    "    yhat = np.where(score[:,1]>score[i,1],1.0,0.0)\n",
    "    TP = np.sum(np.logical_and(yhat==y_test,yhat==1.))\n",
    "    TN = np.sum(np.logical_and(yhat==y_test,yhat==0.))\n",
    "    FP = np.sum(np.logical_and(yhat!=y_test,yhat==1.))\n",
    "    FN = np.sum(np.logical_and(yhat!=y_test,yhat==0.))\n",
    "    alpha = 10\n",
    "    beta = 0.1\n",
    "    balance=-alpha*(TP+FP)+beta*TP*100\n",
    "    \n",
    "    b.append(balance)\n",
    "    \n",
    "    if balance > balance_old:\n",
    "        max_idx = i\n",
    "        balance_old = balance\n",
    "    \n",
    "plt.plot(np.array(b))\n",
    "score[max_idx,1]\n",
    "yhat = np.where(score[:,1]>score[max_idx,1],1.0,0.0)\n",
    "print (metrics.confusion_matrix(yhat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of addressing this problem is by assigning weights to the classes. Let us check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LogisticRegression(class_weight={1:0.0001})\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "yhat = lr.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "c = metrics.confusion_matrix(yhat,y_test)\n",
    "\n",
    "\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = lr.predict_proba(X_test)\n",
    "\n",
    "idx=np.argsort(score[:,1])\n",
    "\n",
    "balance_old = -1e10 \n",
    "max_idx  = 0\n",
    "b = []\n",
    "for i in idx:\n",
    "    yhat = np.where(score[:,1]>score[i,1],1.0,0.0)\n",
    "    TP = np.sum(np.logical_and(yhat==y_test,yhat==1.))\n",
    "    TN = np.sum(np.logical_and(yhat==y_test,yhat==0.))\n",
    "    FP = np.sum(np.logical_and(yhat!=y_test,yhat==1.))\n",
    "    FN = np.sum(np.logical_and(yhat!=y_test,yhat==0.))\n",
    "    alpha = 10\n",
    "    beta = 0.1\n",
    "    balance=-alpha*(TP+FP)+beta*TP*100\n",
    "    \n",
    "    b.append(balance)\n",
    "    \n",
    "    if balance > balance_old:\n",
    "        max_idx = i\n",
    "        balance_old = balance\n",
    "    \n",
    "plt.plot(np.array(b))\n",
    "score[max_idx,1]\n",
    "yhat = np.where(score[:,1]>score[max_idx,1],1.0,0.0)\n",
    "print (metrics.confusion_matrix(yhat,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the best weight and model can be troublesome. Let us introduce our last methodology. We may use model selection checking for the parameters. There are different ways for doing so. The most well known is grid search on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "parameters = {'class_weight' : [{1:0.01},{1:0.1},{1:1},{1:10},{1:100}], 'C':[0.01,0.1,1.,10.,100.]}\n",
    "\n",
    "kf=model_selection.KFold(n_splits=5, shuffle=False, random_state=0)\n",
    "kf.get_n_splits(X)\n",
    "acc = np.zeros((5,))\n",
    "i=0\n",
    "yhat = y.copy()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    #Standard parameters\n",
    "    clf = svm.LinearSVC()\n",
    "    # We can change the scoring \"average_precision\", \"recall\", \"f1\"\n",
    "    clf = model_selection.GridSearchCV(clf, parameters, scoring='precision_macro')\n",
    "    clf.fit(X_train,y_train.ravel())\n",
    "    X_test = scaler.transform(X_test)\n",
    "    yhat[test_index] = clf.predict(X_test)\n",
    "    #recall, f1, precision\n",
    "    acc[i] = metrics.accuracy_score(yhat[test_index], y_test)\n",
    "    print (str(clf.best_params_))\n",
    "    i=i+1\n",
    "print ('Mean accuracy: '+ str(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(yhat,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (metrics.classification_report(y,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-danger\" style = \"border-radius:10px\">**DELIVERABLE: ** Next day we will work on the problem of `Churn?`. Report the best classifier found and their metrics.\n",
    "<p>\n",
    "Some hints\n",
    "<ol>\n",
    "<li>Select one or two classifiers. Some of the most powerful classifiers are `Random Forests`, `SVM with RBF kernel`, and `extreme Gradient Boosting`.</li>\n",
    "<li>Find out what parameters to validate. </li>\n",
    "<li>Grid search and cross validate the problem.</li>\n",
    "</ol>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
