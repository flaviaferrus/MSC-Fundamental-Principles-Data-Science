{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "097cf83b-a6c9-451f-bd15-a2ccb0e38e26",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lesson 7:  Deep Factorization Machines with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c7db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/5g94ghkn0gvbdgjd6vsxlwg40000gn/T/ipykernel_4086/3777615979.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eaa0db3-1d32-4067-bc69-bd1378ad3e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: models: File exists\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "!mkdir models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780bcb6-7381-4a5d-a066-87db5561761a",
   "metadata": {},
   "source": [
    "# DEEP Factorization Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b023dd-09b4-4e7e-87e8-19f4c461a6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "5917549/5917549 [==============================] - 12s 2us/step\n",
      "Extracting all the files now...\n",
      "Done!\n",
      "====== rating.dat ======\n",
      "   uid   mid  rating  timestamp\n",
      "0    1  1193       5  978300760\n",
      "1    1   661       3  978302109\n",
      "2    1   914       3  978301968\n",
      "3    1  3408       4  978300275\n",
      "4    1  2355       5  978824291\n",
      "===== movies.dat ======\n",
      "   mid                          movie_name                   movie_genre\n",
      "0    1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1    2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2    3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3    4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4    5  Father of the Bride Part II (1995)                        Comedy\n",
      "====== users.dat ======\n",
      "   uid user_fea1  user_fea2  user_fea3 user_fea4\n",
      "0    1         F          1         10     48067\n",
      "1    2         M         56         16     70072\n",
      "2    3         M         25         15     55117\n",
      "3    4         M         45          7     02460\n",
      "4    5         M         25         20     55455\n",
      "====== preprocessed data =======\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>mid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>movie_name</th>\n",
       "      <th>movie_genre</th>\n",
       "      <th>user_fea1</th>\n",
       "      <th>user_fea2</th>\n",
       "      <th>user_fea3</th>\n",
       "      <th>user_fea4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>[9, 13, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>[13, 5, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>[9, 2, 0]</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid   mid  rating  timestamp                              movie_name  \\\n",
       "0    1  1193       5  978300760  One Flew Over the Cuckoo's Nest (1975)   \n",
       "1    1   661       3  978302109        James and the Giant Peach (1996)   \n",
       "2    1   914       3  978301968                     My Fair Lady (1964)   \n",
       "3    1  3408       4  978300275                  Erin Brockovich (2000)   \n",
       "4    1  2355       5  978824291                    Bug's Life, A (1998)   \n",
       "\n",
       "  movie_genre user_fea1  user_fea2  user_fea3 user_fea4  \n",
       "0   [1, 0, 0]         F          1         10     48067  \n",
       "1  [9, 13, 0]         F          1         10     48067  \n",
       "2  [13, 5, 0]         F          1         10     48067  \n",
       "3   [1, 0, 0]         F          1         10     48067  \n",
       "4   [9, 2, 0]         F          1         10     48067  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## FACTORIZATION MODELS\n",
    "\n",
    "# Download the actual data from http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "# Use the ratings.csv file\n",
    "movielens_data_file_url = (\n",
    "    \"http://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
    ")\n",
    "movielens_zipped_file = keras.utils.get_file(\n",
    "    \"ml-1m.zip\", movielens_data_file_url, extract=False\n",
    ")\n",
    "keras_datasets_path = Path(movielens_zipped_file).parents[0]\n",
    "movielens_dir = keras_datasets_path / \"ml-1m\"\n",
    "\n",
    "# Only extract the data the first time the script is run.\n",
    "if not movielens_dir.exists():\n",
    "    with ZipFile(movielens_zipped_file, \"r\") as zip:\n",
    "        # Extract files\n",
    "        print(\"Extracting all the files now...\")\n",
    "        zip.extractall(path=keras_datasets_path)\n",
    "        print(\"Done!\")\n",
    "\n",
    "\n",
    "def load_ratings(movielens_dir):\n",
    "    COL_NAME = ['uid','mid','rating','timestamp']\n",
    "    df = pd.read_csv(movielens_dir / 'ratings.dat',sep='::', header=None, engine='python', names=COL_NAME)\n",
    "    return df\n",
    "\n",
    "def load_movies(movielens_dir):\n",
    "    COL_NAME = ['mid','movie_name','movie_genre']\n",
    "    df = pd.read_csv(movielens_dir / 'movies.dat',sep='::', header=None, engine='python', names=COL_NAME, encoding='latin-1')\n",
    "    return df\n",
    "\n",
    "def load_users(movielens_dir):\n",
    "    COL_NAME = ['uid','user_fea1','user_fea2','user_fea3','user_fea4']\n",
    "    df = pd.read_csv(movielens_dir / 'users.dat',sep='::', header=None, engine='python', names=COL_NAME)\n",
    "    return df\n",
    "\n",
    "def text2seq(text, n_genre):\n",
    "    \"\"\" using tokenizer to encoded the multi-level categorical feature\n",
    "    \"\"\"\n",
    "    tokenizer = Tokenizer(lower=True, split='|',filters='', num_words=n_genre)\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    seq = tokenizer.texts_to_sequences(text)\n",
    "    seq = pad_sequences(seq, maxlen=3,padding='post')\n",
    "    return seq\n",
    "\n",
    "n_genre = 15\n",
    "\n",
    "\n",
    "ratings = load_ratings(movielens_dir)\n",
    "movies = load_movies(movielens_dir)\n",
    "users = load_users(movielens_dir)\n",
    "\n",
    "\n",
    "print(\"====== rating.dat ======\")\n",
    "print(ratings.head())\n",
    "print(\"===== movies.dat ======\")\n",
    "print(movies.head())\n",
    "print(\"====== users.dat ======\")\n",
    "print(users.head())\n",
    "\n",
    "movies['movie_genre'] = text2seq(movies.movie_genre.values, n_genre=n_genre).tolist()\n",
    "\n",
    "ratings = ratings.join(movies.set_index('mid'), on = 'mid', how = 'left')\n",
    "ratings = ratings.join(users.set_index('uid'), on = 'uid', how = 'left')\n",
    "print(\"====== preprocessed data =======\")\n",
    "(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f981f6-a90a-4fe4-bfdf-93436e9e039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(ratings, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee0fe4-cc01-42cc-81d0-34dd22299e1c",
   "metadata": {},
   "source": [
    "## Define input layers\n",
    "The dataset contains a **numeric** and **categerical** features, they need to be treated differently.\n",
    "\n",
    "* **numeric features** can be concatenated to inputs, with shape (None, num_of_numeric)\n",
    "* **categorical features** can be encoded individually to inputs, with shape (None, 1) each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce648050-b460-41e6-9e20-aab2c71ad479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "def define_input_layers():\n",
    "    # numerical features\n",
    "    fea3_input = Input((1,), name = 'input_fea3')\n",
    "    num_inputs = [fea3_input]\n",
    "    # single level categorical features\n",
    "    uid_input = Input((1,), name = 'input_uid') #user_id\n",
    "    mid_input = Input((1,), name= 'input_mid')  #movie_id\n",
    "    cat_sl_inputs = [uid_input, mid_input]\n",
    "\n",
    "    # multi level categorical features (with 3 genres at most)\n",
    "    genre_input = Input((3,), name = 'input_genre')\n",
    "    cat_ml_inputs = [genre_input]\n",
    "\n",
    "    inputs = num_inputs + cat_sl_inputs + cat_ml_inputs\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "inputs = define_input_layers()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6174677-bd59-4960-8050-bc1d3aadd383",
   "metadata": {},
   "source": [
    "## 1st order factorization machines\n",
    "1st order will require features to map to a scalar. so for:\n",
    "\n",
    "* numeric feature: a dense layer will convert tensor to shape (None,1)\n",
    "* categorical feature: a embedding layer will convert tensor to shape (None,1,1) and then reshape layer to reshape to (None,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3802ab7-d36f-4a89-848b-8945c579e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-16 12:47:35.151247: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "def Tensor_Mean_Pooling(name = 'mean_pooling', keepdims = False):\n",
    "    return Lambda(lambda x: K.mean(x, axis = 1, keepdims=keepdims), name = name)\n",
    "\n",
    "def fm_1d(inputs, n_uid, n_mid, n_genre):\n",
    "    \n",
    "    # user feat3 + user embedding + movie embedding + genre embedding\n",
    "    fea3_input, uid_input, mid_input, genre_input = inputs\n",
    "    \n",
    "    # all tensors are reshape to (None, 1)\n",
    "    num_dense_1d = [Dense(1, name = 'num_dense_1d_fea4')(fea3_input)]\n",
    "    cat_sl_embed_1d = [Embedding(n_uid + 1, 1, name = 'cat_embed_1d_uid')(uid_input),\n",
    "                        Embedding(n_mid + 1, 1, name = 'cat_embed_1d_mid')(mid_input)]\n",
    "    cat_ml_embed_1d = [Embedding(n_genre + 1, 1, mask_zero=True, name = 'cat_embed_1d_genre')(genre_input)]\n",
    "\n",
    "    cat_sl_embed_1d = [Reshape((1,))(i) for i in cat_sl_embed_1d]\n",
    "    cat_ml_embed_1d = [Tensor_Mean_Pooling(name = 'embed_1d_mean')(i) for i in cat_ml_embed_1d]\n",
    "    \n",
    "    # add all tensors\n",
    "    y_fm_1d = Add(name = 'fm_1d_output')(num_dense_1d + cat_sl_embed_1d + cat_ml_embed_1d)\n",
    "    \n",
    "    return y_fm_1d\n",
    "\n",
    "y_1d = fm_1d(inputs, 10, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9acdd-f8b3-4fcc-aa63-38b3853c8965",
   "metadata": {},
   "source": [
    "## 2nd order factorization machines\n",
    "In 2nd order FM, each feature is map to shape (None, 1, k) and then stack to concat_embed_2d layer with shape (None, p, k).\n",
    "k - matrix factorization latent dimension, p is feature dimension.\n",
    "\n",
    "the calculation of interaction terms can be simplified, using\n",
    "\\begin{equation*} \\sum{x_ix_j} = \\frac{1}{2} \\left((\\sum{x})^2 - \\sum({x}^2)\\right) \\end{equation*}\n",
    "\n",
    "Hence, the sum of 2nd order interactions = square of sum of concat_embed_2d - sum of squared concat_embed_2d in p dimension, the resulting tensor will have a shape (None, k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e3ff7ec-d2d4-489b-a3d5-48d0270757a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_2d(inputs, n_uid, n_mid, n_genre, k):\n",
    "    \n",
    "    fea3_input, uid_input, mid_input, genre_input = inputs\n",
    "    \n",
    "    num_dense_2d = [Dense(k, name = 'num_dense_2d_fea3')(fea3_input)] # shape (None, k)\n",
    "    num_dense_2d = [Reshape((1,k))(i) for i in num_dense_2d] # shape (None, 1, k)\n",
    "\n",
    "    cat_sl_embed_2d = [Embedding(n_uid + 1, k, name = 'cat_embed_2d_uid')(uid_input), \n",
    "                       Embedding(n_mid + 1, k, name = 'cat_embed_2d_mid')(mid_input)] # shape (None, 1, k)\n",
    "    \n",
    "    cat_ml_embed_2d = [Embedding(n_genre + 1, k, name = 'cat_embed_2d_genre')(genre_input)] # shape (None, 3, k)\n",
    "    cat_ml_embed_2d = [Tensor_Mean_Pooling(name = 'cat_embed_2d_genure_mean', keepdims=True)(i) for i in cat_ml_embed_2d] # shape (None, 1, k)\n",
    "\n",
    "    # concatenate all 2d embed layers => (None, ?, k)\n",
    "    embed_2d = Concatenate(axis=1, name = 'concat_embed_2d')(num_dense_2d + cat_sl_embed_2d + cat_ml_embed_2d)\n",
    "\n",
    "    # calcuate the interactions by simplication\n",
    "    # sum of (x1*x2) = sum of (0.5*[(xi)^2 - (xi^2)])\n",
    "    tensor_sum = Lambda(lambda x: K.sum(x, axis = 1), name = 'sum_of_tensors')\n",
    "    tensor_square = Lambda(lambda x: K.square(x), name = 'square_of_tensors')\n",
    "\n",
    "    sum_of_embed = tensor_sum(embed_2d)\n",
    "    square_of_embed = tensor_square(embed_2d)\n",
    "\n",
    "    square_of_sum = Multiply()([sum_of_embed, sum_of_embed])\n",
    "    sum_of_square = tensor_sum(square_of_embed)\n",
    "\n",
    "    sub = Subtract()([square_of_sum, sum_of_square])\n",
    "    sub = Lambda(lambda x: x*0.5)(sub)\n",
    "    y_fm_2d = Reshape((1,), name = 'fm_2d_output')(tensor_sum(sub))\n",
    "    \n",
    "    return y_fm_2d, embed_2d\n",
    "\n",
    "y_fm2_d, embed_2d = fm_2d(inputs, 10, 10, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89dab8-1176-409c-86c8-13d0e0439871",
   "metadata": {},
   "source": [
    "## deep part\n",
    "this part is simply a DNN framework with input as concat_embed_2d layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095f5394-cbf6-449d-b1e2-1c7a7a8de8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_part(embed_2d, dnn_dim, dnn_dr):\n",
    "    \n",
    "    # flat embed layers from 3D to 2D tensors\n",
    "    y_dnn = Flatten(name = 'flat_embed_2d')(embed_2d)\n",
    "    for h in dnn_dim:\n",
    "        y_dnn = Dropout(dnn_dr)(y_dnn)\n",
    "        y_dnn = Dense(h, activation='relu')(y_dnn)\n",
    "    y_dnn = Dense(1, activation='relu', name = 'deep_output')(y_dnn)\n",
    "    \n",
    "    return y_dnn\n",
    "\n",
    "y_dnn = deep_part(embed_2d, [16, 16], 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda1462c-5c6a-4119-b6c4-dd01234170e9",
   "metadata": {},
   "source": [
    "## Put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cffd46d-ff84-4b19-b5d0-f0ef0860b3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_fm_model(n_uid, n_mid, n_genre, k, dnn_dim, dnn_dr):\n",
    "    \n",
    "    inputs = define_input_layers()\n",
    "    \n",
    "    y_fm_1d = fm_1d(inputs, n_uid, n_mid, n_genre)\n",
    "    y_fm_2d, embed_2d = fm_2d(inputs, n_uid, n_mid, n_genre, k)\n",
    "    y_dnn = deep_part(embed_2d, dnn_dim, dnn_dr)\n",
    "    \n",
    "    # combinded deep and fm parts\n",
    "    y = Concatenate()([y_fm_1d, y_fm_2d, y_dnn])\n",
    "    y = Dense(1, name = 'deepfm_output')(y)\n",
    "    \n",
    "    fm_model_1d = Model(inputs, y_fm_1d)\n",
    "    fm_model_2d = Model(inputs, y_fm_2d)\n",
    "    deep_model = Model(inputs, y_dnn)\n",
    "    deep_fm_model = Model(inputs, y)\n",
    "    \n",
    "    return fm_model_1d, fm_model_2d, deep_model, deep_fm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62f13199-0f81-46b5-9350-0d63bd330b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_uid': ratings.uid.max(),\n",
    "    'n_mid': ratings.mid.max(),\n",
    "    'n_genre': 14,\n",
    "    'k':20,\n",
    "    'dnn_dim':[64,64],\n",
    "    'dnn_dr': 0.5\n",
    "}\n",
    "\n",
    "fm_model_1d, fm_model_2d, deep_model, deep_fm_model = deep_fm_model(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08580b64-c5a5-4bc9-bc99-5202688f2145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_uid': 6040,\n",
       " 'n_mid': 3952,\n",
       " 'n_genre': 14,\n",
       " 'k': 20,\n",
       " 'dnn_dim': [64, 64],\n",
       " 'dnn_dr': 0.5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16feee8-07fa-45a7-ae43-d0aeb44166f0",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa13ac7-6109-4256-90cc-16e45ddf20ad",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "008f87b1-624f-4462-9ba8-c60e17190f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2xy(ratings):\n",
    "    x = [ratings.user_fea3.values, \n",
    "         ratings.uid.values, \n",
    "         ratings.mid.values, \n",
    "         np.concatenate(ratings.movie_genre.values).reshape(-1,3)]\n",
    "    y = ratings.rating.values\n",
    "    return x,y\n",
    "\n",
    "train_x, train_y = df2xy(train)\n",
    "valid_x, valid_y = df2xy(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32f9e8-448f-4500-9ff6-c6d335cc722b",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fffc746-7a5a-4b25-b1ed-8ac5c481f535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "391/391 [==============================] - 6s 12ms/step - loss: 4.3003 - val_loss: 6.3736\n",
      "Epoch 2/30\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 1.1593 - val_loss: 2.6351\n",
      "Epoch 3/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 1.0078 - val_loss: 1.4967\n",
      "Epoch 4/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.9436 - val_loss: 1.1172\n",
      "Epoch 5/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.9073 - val_loss: 0.9766\n",
      "Epoch 6/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8854 - val_loss: 0.9143\n",
      "Epoch 7/30\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.8700 - val_loss: 0.8838\n",
      "Epoch 8/30\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.8595 - val_loss: 0.8659\n",
      "Epoch 9/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8517 - val_loss: 0.8583\n",
      "Epoch 10/30\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.8451 - val_loss: 0.8538\n",
      "Epoch 11/30\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.8399 - val_loss: 0.8443\n",
      "Epoch 12/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.8349 - val_loss: 0.8415\n",
      "Epoch 13/30\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.8305 - val_loss: 0.8358\n",
      "Epoch 14/30\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.8256 - val_loss: 0.8309\n",
      "Epoch 15/30\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.8209 - val_loss: 0.8352\n",
      "Epoch 16/30\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.8167 - val_loss: 0.8203\n",
      "Epoch 17/30\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.8117 - val_loss: 0.8164\n",
      "Epoch 18/30\n",
      "391/391 [==============================] - 5s 14ms/step - loss: 0.8072 - val_loss: 0.8143\n",
      "Epoch 19/30\n",
      "391/391 [==============================] - 5s 12ms/step - loss: 0.8032 - val_loss: 0.8118\n",
      "Epoch 20/30\n",
      "391/391 [==============================] - 5s 13ms/step - loss: 0.7994 - val_loss: 0.8082\n",
      "Epoch 21/30\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7968 - val_loss: 0.8057\n",
      "Epoch 22/30\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7936 - val_loss: 0.8054\n",
      "Epoch 23/30\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.7896 - val_loss: 0.8020\n",
      "Epoch 24/30\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.7868 - val_loss: 0.8008\n",
      "Epoch 25/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.7833 - val_loss: 0.7993\n",
      "Epoch 26/30\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.7799 - val_loss: 0.7971\n",
      "Epoch 27/30\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.7759 - val_loss: 0.7951\n",
      "Epoch 28/30\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.7713 - val_loss: 0.7925\n",
      "Epoch 29/30\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.7665 - val_loss: 0.7868\n",
      "Epoch 30/30\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.7604 - val_loss: 0.7825\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import  EarlyStopping, ModelCheckpoint\n",
    "# train  model\n",
    "deep_fm_model.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(learning_rate=0.001)\n",
    ")\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3)\n",
    "model_ckp = ModelCheckpoint(filepath='./models/deepfm_weights.h5', \n",
    "                            monitor='val_loss',\n",
    "                            save_weights_only=True, \n",
    "                            save_best_only=True)\n",
    "callbacks = [model_ckp,early_stop]\n",
    "train_history = deep_fm_model.fit(train_x, train_y, \n",
    "                                  epochs=30, batch_size=2048, \n",
    "                                  validation_data=(valid_x, valid_y),\n",
    "                                  callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4138e0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
