{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea1186e-2624-4389-85ff-ab998ec7330f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## The problem:\n",
    "\n",
    "In order to solve a recommendation problem, we can consider a ranking new problem to be solved. Therefore, in this section we are considering the problem of how to rank the items that we have. \n",
    "\n",
    "## Learning to rank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209ed56-06ed-4931-8b6a-8d29dd471679",
   "metadata": {},
   "source": [
    "The concept is to use Machine Learning in order to **construct a ranking model** form the training data. The problem can be treated as a standard **classification problem**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3f0dcf-f46f-4fcf-b54e-19c846d3eafb",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We are considering optimization techniques that **learn rank-order directly** instead of minimizing a prediction error. \n",
    "\n",
    "We are considering 3 different approaches:\n",
    "- **Pointwise**: (Predict the absolute relevance (e.g. RMSE)) basically predicting out the rank for each singular item.\n",
    "    - We consider as input a single item at a time in the loss function, and train a classifier/regressor on it to predict how relevant it is for the current query/user. The final ranking is achieved by simply sorting the result list by these document scores\n",
    "    - The score for each item is independent of the other items\n",
    "    - All the standard regression and classification algorithms can e directly used for the pointwise learning to rank. \n",
    "    - CONS: Trained minimizing the error on the rating prediction (RMSE,...)\n",
    "        - Point Accuracy $\\neq$ Ranking accuracy! Obtained accuracy is highly biased to popular items.\n",
    "- **Pairwise**: (predict the raking of a document pair, e.g. AUC) the input of the model are **two elements**: item i, item j. And our model will predict $\\pm 1$ depending on whether the order of the input meets the importance order. \n",
    "    - *Instead of focusing on recommendations as a rating prediction problem, it sometimes makes more sense to loot at how the items should be stacked: relative preference*. \n",
    "    - PROS: General criteria: it encodes the order of importance. **General criteria:** the ranking function $f$ leanrs to rank pairs of items!\n",
    "    - CONS: Sometimes this order is really noisy. We would be more focused on the difference between 5 and 4 than between 4 and 1, so why would we spend time optimizing this? Or even 2 and 1. This is, there is no distinction between excellent-bad and fair-bad. \n",
    "    - Several methods: \n",
    "        - RANK SVM, \n",
    "        - RankNet: \n",
    "            - The cost function aims to minimize the number of inversions in ranking. Inversion understood as incorrect order among a pair of results, i.e. when we rank a low rated result above a highier rated result in a ranked list. Optimizes the cost function using SGD. \n",
    "            - Explicit data, like scores. Works with a sigmoid between each two scores i,j. Computes the **cross-entropy** between y and p. The input is two items, so we have two outputs. \n",
    "            - Problem: **the loss is agnostic to the actual ranking of the item**: same pair-level error but different list-level error (it does not depend on the order of the pair on the total distribution, or on the value of the pair, it just compares the difference). \n",
    "        - LambdaRank: instead of taking into account the gradients (indicte the direction we'd like to move an item on a ranking change) of the cross-entropy, it considers a modified function of the gradients NDCG (normalized discounted cumulative gain). \n",
    "            - Faster and more accurate with this normalization of the gradients, compared to the RankNet. \n",
    "            - Consider the normalized gradients: $\\lambda_{ij} = \\frac{-\\Delta(i,j)}{1 + e^{(s_i - s_j)}}$, where $\\Delta(i,j)$ is a penalty corresponding to how bad it is to rank items $i$ and $j$ in the wrong order.\n",
    "        - Bayesian Personalized Ranking: most popular to work with implicit data. It models the relative preferences between different items. \n",
    "            - Problem: the BPR does not sufficiently penalize the items that are at a lower rank. \n",
    "- **Listwise**: (predict the ranking of a document list based on a feature vector $x$, e.g. cross entropy) instead of using pairs we are using lists. We have then as input the user features, and a list of n examples. Then the output may be the rank. \n",
    "    - Advantage: positional information is visible to the loss function\n",
    "    - Problem: really complexity when training\n",
    "    - Some examples: \n",
    "        - transformers networks (deep learning)\n",
    "        - LambdaMart: combines LambdaRank and MART (Mutliple Additive Regression Trees). MART uses gradient boosted decision trees for prediction tasks. LambdaMART uses gradient boosted decision trees using a cost function derived from LAmbdaRank for solving the ranking task. \n",
    "    \n",
    "LTR are great but really task consuming: for learning but also for final decision. Consider this situation, in which we have a list of relevant samples which we need in fact to reorder so we can make a final decision. It is an expensive and complex process just to get a list of 10 recommendations at the end. \n",
    "\n",
    "If we have implicit data (we donnot have given the output we want to predict) we have more complex process to get the actual preferences from the user and from the data we have. We also have not observed items, are they as relevant as the seen ones? Sometimes we just do not have the actual answer for this question. However we have information from the items he bought (maybe). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09271065-43cb-4f4c-9185-1c345c7302f1",
   "metadata": {},
   "source": [
    "# Deliveries\n",
    "\n",
    "- Challenge\n",
    "- Presentations\n",
    "- Notebook provided by Paula (we would need to finish it in class)\n",
    "\n",
    "# Presentations:\n",
    "\n",
    "Paper presentations: 8-10 minutes (26th) \n",
    "Paper suggestions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54afd1-bbbd-4453-bfd6-039a8f4f1a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
