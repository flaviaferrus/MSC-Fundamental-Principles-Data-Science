{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ddcb657-8869-438d-97b1-924ce32a2d5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Challenge\n",
    "\n",
    "We want to recommend 25 movies per user. \n",
    "\n",
    "Best method in terms of the average precision. \n",
    "\n",
    "The relevant are the ones on the top 15% of each user. So for each user we select 15% highier score. We need to find the 25 with the more likelihood to be chosen. \n",
    "\n",
    "Item-item regression: take into account that we are doing well for those items that are really good for the user. \n",
    "\n",
    "Consider the classical gaussian distribution for each user, going from 1 to 5: we only take into account the ones on the last percentile (closer to 5). In the root square error we consider the ones on the middle to have more weigth, but we are interested on the ones closer the highier marks. Using the item-item regression we can train the model we can focus on those. \n",
    "\n",
    "Better root square error does no provide a better mark on this kaggle competition! We may be using another mark! \n",
    "\n",
    "He looks for shorter code with a lot of justifications (discussion is more important than the code). \n",
    "\n",
    "Sampling the data may be more important than training or preparing the model. It is important to know how to optimize the training, and focusing on the top rated movies per user!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679197d-85f1-4f27-b927-0b161275b582",
   "metadata": {},
   "source": [
    "Each user has different threshold for the top rated movie. The submission must be 25 highier movies per user:\n",
    "\n",
    "`user_id: [ ... ] ` \n",
    "\n",
    "So if the top rated movies are in this list, it is taken into account:\n",
    "\n",
    "`recommender system precision:`$=p = \\frac{N}{n}$, $N=$ number of our recommendations that are relevant, $n=$ number of items we recommend. \n",
    "\n",
    "`recommender system call:` $r = \\frac{N}{R}$, $R=$ number of all the possoble relevant items. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cc6ef2-3cd7-411d-881e-059521e202d1",
   "metadata": {},
   "source": [
    "We should not recommend elements that have already been used on the training set (elements are either on the training or on the test set). \n",
    "\n",
    "We consider the average precision as the metrics to evaluate our model. \n",
    "\n",
    "## Average precision:\n",
    "\n",
    "AP@N $= \\frac{1}{m} \\sum_{i=1}^N  $\n",
    "\n",
    "Taking into account this metrics, the order of the list is important!\n",
    "\n",
    "### Case\n",
    "relevant: `[1,3,5,8]`\n",
    "\n",
    "recomm: `[1,7,8]` -> precision: `[1,0,1]` -> average precision \n",
    "\n",
    "recomm: `[7,1,8]` -> precision: `[0,1,1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916d80f4-fb6e-41d4-9124-61af208cc080",
   "metadata": {},
   "source": [
    "## Collaborative notebook\n",
    "\n",
    "Provides poor results. \n",
    "\n",
    "The similarities are computed using the cosine. This code is faster than the one seen on Monday but provides poor results. \n",
    "- User based recommendation: similarities between other users: $U \\times U$ matrices. \n",
    "- Item based version: similaritios stored in $I \\times I$ matrices\n",
    "After computing the similarities, the prediction corresponds to: \n",
    "- User based: `score(U, i) = sim(U) * urm(:, i).T` ($U\\times i$ matrix, dot product $U \\times U$ matrix ). The output is the dot product between these two vectors. \n",
    "- Item based: `score( i) = sim(U) * urm(U, :).T`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0b0fa0-4e7c-4409-bac6-647efb4d8afb",
   "metadata": {},
   "source": [
    "## Results:\n",
    "\n",
    "When studying the results, we have to validate whether they actually make sense: are we finding intuitive similarities. We can study some cases. It is also interesting to study what happens with the movies that are not popular. What grade do they have if they are not popular?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf68286-0974-4d55-a021-c06c0ea2a211",
   "metadata": {},
   "source": [
    "## Ideas \n",
    "\n",
    "- Normalització prèvia al model: \n",
    "     - Gaussiana centrada al 0 (de -1 a 1, per tal de deixar a fora els negatius i donar pesos menors als valors pròxims al 0 de la gaussiana, que tot i ser més amb el menor pes es tinguin en compte de manera escasa)\n",
    "     - Normalització de min/max (de 0 a 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a4dff-2217-47f6-acec-a605aa300f46",
   "metadata": {},
   "source": [
    "## To Do's\n",
    "\n",
    "- És molt important donar-li el pes que es mereix a les top pelis de cada usuari. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
