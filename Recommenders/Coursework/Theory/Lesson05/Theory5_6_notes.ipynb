{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "481023f0-0556-4748-9e25-092676b01ce5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Collaborative based Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81fe19-c715-4d49-807e-4fc20b55317a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Factorizations Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5df2fa-f3e3-42e3-8cf3-97ace56ef7f0",
   "metadata": {},
   "source": [
    "**Matrix factorization is a simple embedding model, which decomposes the user-item intraction matrix**, $R \\in R^{m\\times n}$ matrix, where $m$ is the number of users and $n$ the number of items, into the product of two lower dimensionality rectangular matrice. The goal of the factorization models is to learn:\n",
    "* A user embedding (or user latent factor) $P \\in R^{m\\times k}$, where row $i$ is the embedding of user $i$.\n",
    "* A item embedding (or item latent factor) $Q \\in R^{n\\times k}$, where row $j$ is the embedding of user $j$.\n",
    "\n",
    "![alt factorization models](https://miro.medium.com/max/988/1*nIVWl2ROaxOY23hHajkTTg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa7d8c6-d5ce-486b-b176-4a1fc16d572d",
   "metadata": {},
   "source": [
    "There are different approaches to solve a recommender problem using factorization models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43754800-4d9a-4a4f-9238-a4f7625d4f48",
   "metadata": {},
   "source": [
    "### SVD Decomposition\n",
    "\n",
    "Singular Value Decomposition (SVD) is a well established technique for **identifying latent semantic factors**. Done by **factorizing the user-item rating matrix**.\n",
    "\n",
    "The singular value decomposition is a methods that decomposes a matrix into three other matrices as given below:\n",
    "$$ R = USV^T$$\n",
    "\n",
    "Where\n",
    "* $R$ is a $m\\times n$ rating matrix;\n",
    "* $U$ is a $m\\times k$ orthogonal left singular matrix, which **represents the relationship between users and latent factors** and it is known **user latent matrix**;\n",
    "* $S$ is a $r\\times r$ diagonal matrix, whcih describes the **strengh of each latent factor**, and;\n",
    "* $V$ is a $n \\times k$ orthogonal right singular matrix, which represents the **relationship between items and latent factors** and it is known **item latent matrix**.\n",
    "\n",
    "Columns of U and V are constrained to be mutually orthogonal. \n",
    "\n",
    "Mutual orthogonality has the advantage that the concepts can be completely independent of one another. Can be interpreted in scatterplots\n",
    "\n",
    "APPROACH: \n",
    "1. Initialization: Initialize the missing entries in the ith row of R to be the mean μi of that row to create Rf .\n",
    "2. Iterative step 1: Perform rank-k SVD of Rf in the form QkΣkPkT \n",
    "3. Iterative step 2: Readjust only the (originally) missing entries of Rf to the corresponding values in QkΣkPkT . Go to iterative step 1\n",
    "\n",
    "**Problem**: $R$ matrix needs to be complete in order to be decomposed\n",
    "* Solution: fill missing values with the mean rating of the user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d6748b-ed2b-4468-856e-0e032bb640a8",
   "metadata": {},
   "source": [
    "### The Vanilla Matrix Factorization Model \n",
    "* Also know as **Funk SVD**\n",
    "* * Despite its name, in Funk SVD, no singular value decomposition is applied.\n",
    "* * https://sifter.org/simon/journal/20061211.html\n",
    "\n",
    "**A straightforward matrix factorization model maps both users and items to a joint latent factor space of dimensionality D. User-item interaction are modeled as inner products in that space**\n",
    "$$R = UV$$\n",
    "\n",
    "Each item j is associated with a vector $v_j$ from $V$, and each user $i$ is associated with a vecor $u_i$ from $U$.\n",
    "The resulting dot product $u_i\\cdot v_j$ captures the interaction between the user $i$ and item $j$:\n",
    "$$ \\hat{r} = u_i\\cdot v_j$$\n",
    "\n",
    "The goal of the matrix factorization consist on finding the mapping of each item and user to factors $u_i$ and $v_j$. To do so, the minimization the of squarred error function is performed:\n",
    "$$ \\sum(R_{ui} - u_i\\cdot v_j)^2$$\n",
    "\n",
    "This factorization can be learnt using **only those known ratings**. We do not need to infer missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eba438-e5d5-4eec-bb6e-366bb198b711",
   "metadata": {},
   "source": [
    "![alt Amazon](https://miro.medium.com/max/4800/1*b4M7o7W8bfRRxdMxtFoVBQ.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ea0bc9-3d8a-48fa-8ad6-c8ec7dbcf75b",
   "metadata": {},
   "source": [
    "### The Vanilla Matrix Factorization Model with biases \n",
    "\n",
    "* Despite its name, in SVD, no singular value decomposition is applied.\n",
    "\n",
    "\n",
    "Now the model is defined as:\n",
    "$\\hat{r}_{ui} = \\bar{r} + b_{u_u} + b_{i_i}  \\sum_{k = 1}^KP_{uk} Q_{ik}^T  $\n",
    "\n",
    "To learn the model we can use the SGD as before. Now the latent factors and biases are updated as follows:\n",
    "* $error = r -\\hat{r}$\n",
    "* $b_{u_u} = b_{u_u} + \\alpha*(error -  \\lambda*b_{u_u})$\n",
    "* $b_{i_i} = b_{i_i} + \\alpha*(error -  \\lambda*b_{i_i})$\n",
    "* $P_{uk} = P_{uk} + \\alpha*(error*Q_{ik} -  \\lambda*P_{uk})$\n",
    "* $Q_{ik} = Q_{ik} + \\alpha*(error*P_{uk} -  \\lambda*Q_{ik})$\n",
    "\n",
    "where $\\alpha$ is the learning rate and $\\lambda$ is the regularization term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e256654-b72f-492b-87fe-5e6d020f3b7d",
   "metadata": {},
   "source": [
    "### SVD++\n",
    "\n",
    "We are adding a vector which accounts for the importance of observing an item ($y_i$), learning how important it is to have seen an important item. If the user has seen a lot of movies but not much important, it would not be taken into account with that much weight. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ab2763-b723-4741-9b34-bd52b7fe439b",
   "metadata": {},
   "source": [
    "## Factorization Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789fd318-0400-4280-99ad-8eb3fedd7d59",
   "metadata": {},
   "source": [
    "Summary here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331f59b7-c6ab-4463-88dc-27f21ca19753",
   "metadata": {},
   "source": [
    "### Deep Factorization Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e931e07-4246-4d57-9e40-bb467dee15e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
